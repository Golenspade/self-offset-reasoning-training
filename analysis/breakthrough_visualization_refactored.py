"""
æ–‡ä»¶å: breakthrough_visualization_refactored.py
é‡æ„åçš„çªç ´æ€§è®­ç»ƒå¯è§†åŒ–
åŸºäºçœŸå®æ•°æ®çš„è¯šå®å¯è§†åŒ–ï¼Œç§»é™¤è™šæ„å†…å®¹å’Œè¯¯å¯¼æ€§æŒ‡æ ‡

ä¸»è¦æ”¹è¿›ï¼š
1. ç§»é™¤è™šæ„çš„"ä¸‰é˜¶æ®µæ”¹è¿›å¯¹æ¯”"å›¾è¡¨
2. ä¿®å¤é›·è¾¾å›¾ä¸­çš„ä»£ç†æŒ‡æ ‡é—®é¢˜
3. å¢å¼ºæ•°æ®å¥å£®æ€§æ£€æŸ¥
4. ä¼˜åŒ–æ•°æ®é¢„å¤„ç†
5. ç§»é™¤æ— æ•ˆçš„reportåŠ è½½
"""

import json
import numpy as np
import matplotlib.pyplot as plt
import matplotlib.font_manager as fm
from pathlib import Path
import logging

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'SimHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False


def load_breakthrough_data():
    """
    åŠ è½½çªç ´æ€§è®­ç»ƒæ•°æ®
    åªåŠ è½½å®é™…ä½¿ç”¨çš„è®­ç»ƒå†å²æ•°æ®
    """
    history_path = 'outputs/breakthrough_training/training_history.json'
    
    try:
        with open(history_path, 'r') as f:
            history = json.load(f)
        logger.info(f"âœ… æˆåŠŸåŠ è½½è®­ç»ƒå†å²æ•°æ®: {history_path}")
        return history
    except FileNotFoundError:
        logger.error(f"âŒ è®­ç»ƒå†å²æ–‡ä»¶æœªæ‰¾åˆ°: {history_path}")
        raise
    except json.JSONDecodeError as e:
        logger.error(f"âŒ JSONè§£æé”™è¯¯: {e}")
        raise


def preprocess_metrics_data(history):
    """
    é¢„å¤„ç†æŒ‡æ ‡æ•°æ®ï¼Œå°†å¤æ‚çš„åµŒå¥—ç»“æ„è½¬æ¢ä¸ºæ˜“äºè®¿é—®çš„æ ¼å¼
    
    Args:
        history: è®­ç»ƒå†å²æ•°æ®
        
    Returns:
        dict: é¢„å¤„ç†åçš„æŒ‡æ ‡æ•°æ®
    """
    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
    if 'breakthrough_metrics' not in history:
        logger.warning("âš ï¸ è®­ç»ƒå†å²ä¸­ç¼ºå°‘breakthrough_metricsæ•°æ®")
        return {}
    
    breakthrough_metrics = history['breakthrough_metrics']
    if not breakthrough_metrics:
        logger.warning("âš ï¸ breakthrough_metricsä¸ºç©º")
        return {}
    
    # æå–æ‰€æœ‰å¯èƒ½çš„æŒ‡æ ‡åç§°
    all_metric_names = set()
    for metrics in breakthrough_metrics:
        if isinstance(metrics, dict):
            all_metric_names.update(metrics.keys())
    
    # æ„å»ºæ—¶é—´åºåˆ—æ•°æ®
    metrics_over_time = {}
    for metric_name in all_metric_names:
        metrics_over_time[metric_name] = []
        for metrics in breakthrough_metrics:
            if isinstance(metrics, dict):
                metrics_over_time[metric_name].append(metrics.get(metric_name, 0.0))
            else:
                metrics_over_time[metric_name].append(0.0)
    
    logger.info(f"âœ… é¢„å¤„ç†å®Œæˆï¼Œæå–åˆ° {len(all_metric_names)} ä¸ªæŒ‡æ ‡")
    return metrics_over_time


def validate_data_completeness(history):
    """
    éªŒè¯æ•°æ®å®Œæ•´æ€§ï¼Œç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è¿›è¡Œå¯è§†åŒ–
    
    Args:
        history: è®­ç»ƒå†å²æ•°æ®
        
    Returns:
        dict: éªŒè¯ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯
    """
    validation_result = {
        'is_valid': True,
        'warnings': [],
        'stats': {}
    }
    
    # æ£€æŸ¥åŸºæœ¬è®­ç»ƒæ•°æ®
    required_fields = ['train_loss', 'val_loss', 'epochs']
    for field in required_fields:
        if field not in history:
            validation_result['is_valid'] = False
            validation_result['warnings'].append(f"ç¼ºå°‘å¿…éœ€å­—æ®µ: {field}")
        elif not history[field]:
            validation_result['warnings'].append(f"å­—æ®µä¸ºç©º: {field}")
        else:
            validation_result['stats'][field] = len(history[field])
    
    # æ£€æŸ¥æ•°æ®é•¿åº¦ä¸€è‡´æ€§
    if all(field in history for field in required_fields):
        lengths = [len(history[field]) for field in required_fields]
        if len(set(lengths)) > 1:
            validation_result['warnings'].append(f"æ•°æ®é•¿åº¦ä¸ä¸€è‡´: {dict(zip(required_fields, lengths))}")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„æ•°æ®ç‚¹è¿›è¡Œåˆ†æ
    if 'train_loss' in history and len(history['train_loss']) < 2:
        validation_result['warnings'].append("è®­ç»ƒæ•°æ®ç‚¹è¿‡å°‘ï¼Œæ— æ³•è®¡ç®—æ”¹è¿›è¶‹åŠ¿")
    
    return validation_result


def create_breakthrough_visualization():
    """åˆ›å»ºåŸºäºçœŸå®æ•°æ®çš„çªç ´æ€§è®­ç»ƒå¯è§†åŒ–"""
    
    # åŠ è½½å’ŒéªŒè¯æ•°æ®
    history = load_breakthrough_data()
    validation = validate_data_completeness(history)
    
    if not validation['is_valid']:
        logger.error("âŒ æ•°æ®éªŒè¯å¤±è´¥ï¼Œæ— æ³•ç”Ÿæˆå¯è§†åŒ–")
        for warning in validation['warnings']:
            logger.error(f"  - {warning}")
        return
    
    # è¾“å‡ºè­¦å‘Šä¿¡æ¯
    for warning in validation['warnings']:
        logger.warning(f"âš ï¸ {warning}")
    
    # é¢„å¤„ç†æŒ‡æ ‡æ•°æ®
    metrics_over_time = preprocess_metrics_data(history)
    
    # åˆ›å»ºå›¾è¡¨ - è°ƒæ•´ä¸º2x3å¸ƒå±€ï¼Œç§»é™¤è™šæ„çš„ä¸‰é˜¶æ®µå¯¹æ¯”å›¾
    fig = plt.figure(figsize=(18, 12))
    fig.suptitle('ğŸ“Š çªç ´æ€§è®­ç»ƒç³»ç»Ÿ - çœŸå®æ•°æ®å¯è§†åŒ–æŠ¥å‘Š', 
                 fontsize=20, fontweight='bold', y=0.98)
    
    # å®‰å…¨è·å–æ•°æ®
    epochs = history.get('epochs', [])
    train_loss = history.get('train_loss', [])
    val_loss = history.get('val_loss', [])
    
    # 1. è®­ç»ƒæŸå¤±è¶‹åŠ¿
    ax1 = plt.subplot(2, 3, 1)
    if len(epochs) > 0 and len(train_loss) > 0:
        ax1.plot(epochs, train_loss, 'b-', linewidth=2, label='è®­ç»ƒæŸå¤±', alpha=0.8)
        if len(val_loss) > 0:
            ax1.plot(epochs, val_loss, 'r-', linewidth=2, label='éªŒè¯æŸå¤±', alpha=0.8)
        
        ax1.set_title('ğŸ“‰ æŸå¤±æ›²çº¿', fontsize=14, fontweight='bold')
        ax1.set_xlabel('Epoch')
        ax1.set_ylabel('æŸå¤±å€¼')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # æ·»åŠ æ”¹è¿›ç»Ÿè®¡
        if len(train_loss) > 1:
            improvement = (train_loss[0] - train_loss[-1]) / train_loss[0] * 100
            ax1.text(0.02, 0.98, f'è®­ç»ƒæŸå¤±æ”¹è¿›: {improvement:.1f}%', 
                    transform=ax1.transAxes, fontsize=10, 
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightblue", alpha=0.7),
                    verticalalignment='top')
    else:
        ax1.text(0.5, 0.5, 'âŒ æŸå¤±æ•°æ®ä¸è¶³', ha='center', va='center', 
                transform=ax1.transAxes, fontsize=12)
        ax1.set_title('ğŸ“‰ æŸå¤±æ›²çº¿ (æ•°æ®ä¸è¶³)', fontsize=14)
    
    # 2. å­¦ä¹ ç‡å˜åŒ–
    ax2 = plt.subplot(2, 3, 2)
    learning_rates = history.get('learning_rate', [])
    if len(epochs) > 0 and len(learning_rates) > 0:
        ax2.plot(epochs, learning_rates, 'g-', linewidth=2, alpha=0.8)
        ax2.set_title('ğŸ“ˆ å­¦ä¹ ç‡è°ƒåº¦', fontsize=14, fontweight='bold')
        ax2.set_xlabel('Epoch')
        ax2.set_ylabel('å­¦ä¹ ç‡')
        ax2.grid(True, alpha=0.3)
        ax2.set_yscale('log')  # ä½¿ç”¨å¯¹æ•°åˆ»åº¦æ›´å¥½åœ°æ˜¾ç¤ºå­¦ä¹ ç‡å˜åŒ–
    else:
        ax2.text(0.5, 0.5, 'âŒ å­¦ä¹ ç‡æ•°æ®ä¸è¶³', ha='center', va='center', 
                transform=ax2.transAxes, fontsize=12)
        ax2.set_title('ğŸ“ˆ å­¦ä¹ ç‡è°ƒåº¦ (æ•°æ®ä¸è¶³)', fontsize=14)
    
    # 3. æ¢¯åº¦å¥åº·åº¦
    ax3 = plt.subplot(2, 3, 3)
    gradient_health = metrics_over_time.get('gradient_health', [])
    if len(epochs) > 0 and len(gradient_health) > 0:
        ax3.plot(epochs, gradient_health, 'purple', linewidth=2, alpha=0.8)
        ax3.set_title('ğŸ§  æ¢¯åº¦å¥åº·åº¦', fontsize=14, fontweight='bold')
        ax3.set_xlabel('Epoch')
        ax3.set_ylabel('å¥åº·åº¦')
        ax3.set_ylim(0, 1.1)
        ax3.grid(True, alpha=0.3)
        
        # æ·»åŠ å¥åº·åº¦ç»Ÿè®¡
        if gradient_health:
            avg_health = np.mean(gradient_health)
            ax3.axhline(y=avg_health, color='red', linestyle='--', alpha=0.7, 
                       label=f'å¹³å‡å€¼: {avg_health:.3f}')
            ax3.legend()
    else:
        ax3.text(0.5, 0.5, 'âŒ æ¢¯åº¦å¥åº·åº¦æ•°æ®ä¸è¶³', ha='center', va='center', 
                transform=ax3.transAxes, fontsize=12)
        ax3.set_title('ğŸ§  æ¢¯åº¦å¥åº·åº¦ (æ•°æ®ä¸è¶³)', fontsize=14)
    
    # 4. å†…å­˜åˆ©ç”¨ç‡
    ax4 = plt.subplot(2, 3, 4)
    memory_utilization = history.get('memory_utilization', [])
    if len(epochs) > 0 and len(memory_utilization) > 0:
        ax4.plot(epochs, memory_utilization, 'orange', linewidth=2, alpha=0.8)
        ax4.set_title('ğŸ’¾ å†…å­˜åˆ©ç”¨ç‡', fontsize=14, fontweight='bold')
        ax4.set_xlabel('Epoch')
        ax4.set_ylabel('åˆ©ç”¨ç‡')
        ax4.set_ylim(0, 1.1)
        ax4.grid(True, alpha=0.3)
        
        # æ·»åŠ åˆ©ç”¨ç‡ç»Ÿè®¡
        if memory_utilization:
            final_util = memory_utilization[-1]
            ax4.text(0.02, 0.98, f'æœ€ç»ˆåˆ©ç”¨ç‡: {final_util:.2f}', 
                    transform=ax4.transAxes, fontsize=10,
                    bbox=dict(boxstyle="round,pad=0.3", facecolor="lightyellow", alpha=0.7),
                    verticalalignment='top')
    else:
        ax4.text(0.5, 0.5, 'âŒ å†…å­˜åˆ©ç”¨ç‡æ•°æ®ä¸è¶³', ha='center', va='center', 
                transform=ax4.transAxes, fontsize=12)
        ax4.set_title('ğŸ’¾ å†…å­˜åˆ©ç”¨ç‡ (æ•°æ®ä¸è¶³)', fontsize=14)
    
    # 5. çœŸå®æ€§èƒ½é›·è¾¾å›¾ (ä¿®å¤åçš„ç‰ˆæœ¬)
    ax5 = plt.subplot(2, 3, 5, projection='polar')
    
    # è·å–æœ€ç»ˆæŒ‡æ ‡ (å¦‚æœæœ‰æ•°æ®çš„è¯)
    if metrics_over_time and any(len(values) > 0 for values in metrics_over_time.values()):
        # åªä½¿ç”¨çœŸå®çš„ã€æœ‰æ„ä¹‰çš„æŒ‡æ ‡
        categories = []
        values = []
        
        # å®šä¹‰çœŸå®æŒ‡æ ‡åŠå…¶è·å–æ–¹å¼
        real_metrics = {
            'ç¨³å®šæ€§': metrics_over_time.get('stability_score', []),
            'è®°å¿†åˆ©ç”¨ç‡': history.get('memory_utilization', []),
            'æ¢¯åº¦å¥åº·': metrics_over_time.get('gradient_health', [])
        }
        
        for category, metric_values in real_metrics.items():
            if metric_values:  # åªæ·»åŠ æœ‰æ•°æ®çš„æŒ‡æ ‡
                categories.append(category)
                values.append(metric_values[-1])  # ä½¿ç”¨æœ€ç»ˆå€¼
        
        if categories and values:
            # é—­åˆé›·è¾¾å›¾
            angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
            values += values[:1]  # é—­åˆ
            angles += angles[:1]  # é—­åˆ
            
            ax5.plot(angles, values, 'o-', linewidth=2, color='red', alpha=0.8)
            ax5.fill(angles, values, alpha=0.25, color='red')
            ax5.set_xticks(angles[:-1])
            ax5.set_xticklabels(categories)
            ax5.set_ylim(0, 1)
            ax5.set_title('ğŸ¯ çœŸå®æ€§èƒ½æŒ‡æ ‡\n(åŸºäºæœ€ç»ˆè®­ç»ƒç»“æœ)', fontsize=14, fontweight='bold', pad=20)
            ax5.grid(True)
        else:
            ax5.text(0.5, 0.5, 'âŒ æ€§èƒ½æŒ‡æ ‡æ•°æ®ä¸è¶³', ha='center', va='center', 
                    transform=ax5.transAxes, fontsize=12)
            ax5.set_title('ğŸ¯ çœŸå®æ€§èƒ½æŒ‡æ ‡ (æ•°æ®ä¸è¶³)', fontsize=14)
    else:
        ax5.text(0.5, 0.5, 'âŒ æ€§èƒ½æŒ‡æ ‡æ•°æ®ä¸è¶³', ha='center', va='center', 
                transform=ax5.transAxes, fontsize=12)
        ax5.set_title('ğŸ¯ çœŸå®æ€§èƒ½æŒ‡æ ‡ (æ•°æ®ä¸è¶³)', fontsize=14)
    
    # 6. è®­ç»ƒç»Ÿè®¡æ‘˜è¦
    ax6 = plt.subplot(2, 3, 6)
    ax6.axis('off')  # éšè—åæ ‡è½´
    
    # è®¡ç®—çœŸå®çš„è®­ç»ƒç»Ÿè®¡
    stats_text = "ğŸ“Š è®­ç»ƒç»Ÿè®¡æ‘˜è¦\n\n"
    
    if validation['stats']:
        stats_text += f"æ•°æ®ç‚¹æ•°é‡: {validation['stats'].get('epochs', 0)}\n"
    
    if len(train_loss) > 1:
        initial_loss = train_loss[0]
        final_loss = train_loss[-1]
        improvement = (initial_loss - final_loss) / initial_loss * 100
        stats_text += f"è®­ç»ƒæŸå¤±æ”¹è¿›: {improvement:.1f}%\n"
        stats_text += f"åˆå§‹æŸå¤±: {initial_loss:.4f}\n"
        stats_text += f"æœ€ç»ˆæŸå¤±: {final_loss:.4f}\n"
    
    if len(val_loss) > 1:
        best_val_loss = min(val_loss)
        stats_text += f"æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}\n"
    
    if gradient_health:
        avg_gradient_health = np.mean(gradient_health)
        stats_text += f"å¹³å‡æ¢¯åº¦å¥åº·åº¦: {avg_gradient_health:.3f}\n"
    
    if memory_utilization:
        final_memory_util = memory_utilization[-1]
        stats_text += f"æœ€ç»ˆå†…å­˜åˆ©ç”¨ç‡: {final_memory_util:.3f}\n"
    
    # æ·»åŠ æ•°æ®è´¨é‡ä¿¡æ¯
    if validation['warnings']:
        stats_text += f"\nâš ï¸ æ•°æ®è´¨é‡è­¦å‘Š:\n"
        for warning in validation['warnings'][:3]:  # åªæ˜¾ç¤ºå‰3ä¸ªè­¦å‘Š
            stats_text += f"â€¢ {warning}\n"
    
    ax6.text(0.05, 0.95, stats_text, transform=ax6.transAxes, fontsize=11,
             verticalalignment='top', fontfamily='monospace',
             bbox=dict(boxstyle="round,pad=0.5", facecolor="lightgray", alpha=0.8))
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_path = 'outputs/breakthrough_training/breakthrough_visualization_honest.png'
    Path(output_path).parent.mkdir(parents=True, exist_ok=True)
    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')
    logger.info(f"âœ… å¯è§†åŒ–å›¾è¡¨å·²ä¿å­˜: {output_path}")
    
    plt.show()
    
    return fig


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ“Š å¯åŠ¨é‡æ„åçš„çªç ´æ€§è®­ç»ƒå¯è§†åŒ–")
    print("=" * 60)
    print("ğŸ¯ ç‰¹ç‚¹:")
    print("  âœ… åŸºäºçœŸå®è®­ç»ƒæ•°æ®")
    print("  âœ… ç§»é™¤è™šæ„çš„æ”¹è¿›å¯¹æ¯”")
    print("  âœ… ä¿®å¤è¯¯å¯¼æ€§æŒ‡æ ‡")
    print("  âœ… å¢å¼ºæ•°æ®å¥å£®æ€§")
    print("  âœ… è¯šå®çš„æ€§èƒ½å±•ç¤º")
    print("=" * 60)
    
    try:
        fig = create_breakthrough_visualization()
        print("\nğŸ‰ å¯è§†åŒ–ç”Ÿæˆå®Œæˆ!")
        print("ğŸ“ è¾“å‡ºæ–‡ä»¶: outputs/breakthrough_training/breakthrough_visualization_honest.png")
        
    except Exception as e:
        logger.error(f"âŒ å¯è§†åŒ–ç”Ÿæˆå¤±è´¥: {e}")
        raise


if __name__ == "__main__":
    main()
