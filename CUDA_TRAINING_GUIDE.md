# ğŸš€ CUDAåŠ é€Ÿè®­ç»ƒä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨è‡ªåç§»æ¨ç†è®­ç»ƒé¡¹ç›®çš„CUDAåŠ é€ŸåŠŸèƒ½ï¼Œå®ç°GPUé«˜æ€§èƒ½è®­ç»ƒã€‚

## ğŸ¯ CUDAç³»ç»Ÿç‰¹æ€§

### âš¡ æ ¸å¿ƒä¼˜åŒ–ç‰¹æ€§
- **è‡ªåŠ¨è®¾å¤‡æ£€æµ‹**: æ™ºèƒ½é€‰æ‹©æœ€ä½³GPUè®¾å¤‡
- **æ··åˆç²¾åº¦è®­ç»ƒ**: FP16åŠ é€Ÿè®­ç»ƒï¼ŒèŠ‚çœå†…å­˜
- **å†…å­˜ç®¡ç†**: æ™ºèƒ½GPUå†…å­˜åˆ†é…å’Œæ¸…ç†
- **æ‰¹æ¬¡ä¼˜åŒ–**: æ ¹æ®GPUå†…å­˜è‡ªåŠ¨è°ƒæ•´æ‰¹æ¬¡å¤§å°
- **æ¢¯åº¦ç´¯ç§¯**: æ”¯æŒå¤§æ‰¹æ¬¡ç­‰æ•ˆè®­ç»ƒ
- **æ€§èƒ½ç›‘æ§**: å®æ—¶GPUä½¿ç”¨ç‡å’Œå†…å­˜ç›‘æ§

### ğŸ—ï¸ ç³»ç»Ÿæ¶æ„
```
CUDAå·¥å…·å±‚ (cuda_utils.py)
    â†“
æ¨¡å‹å±‚ (model.py + CUDAæ”¯æŒ)
    â†“
è®­ç»ƒç³»ç»Ÿå±‚ (cuda_training_system.py)
    â†“
ä¸»è®­ç»ƒè„šæœ¬ (train_cuda.py)
```

## ğŸ› ï¸ ç¯å¢ƒå‡†å¤‡

### 1. ç¡¬ä»¶è¦æ±‚
- **GPU**: NVIDIA GPU (è®¡ç®—èƒ½åŠ› >= 6.0)
- **å†…å­˜**: æ¨è >= 8GB GPUå†…å­˜
- **CUDA**: CUDA 11.8 æˆ–æ›´é«˜ç‰ˆæœ¬

### 2. è½¯ä»¶ä¾èµ–å®‰è£…

#### åŸºç¡€ç¯å¢ƒ
```bash
# ç¡®ä¿æœ‰NVIDIAé©±åŠ¨å’ŒCUDA
nvidia-smi  # æ£€æŸ¥GPUçŠ¶æ€
nvcc --version  # æ£€æŸ¥CUDAç‰ˆæœ¬
```

#### Pythonä¾èµ–
```bash
# å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118

# å®‰è£…å…¶ä»–CUDAä¾èµ–
pip install -r requirements_cuda.txt
```

#### éªŒè¯å®‰è£…
```bash
python3 -c "import torch; print(f'CUDAå¯ç”¨: {torch.cuda.is_available()}'); print(f'GPUæ•°é‡: {torch.cuda.device_count()}')"
```

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒæ£€æŸ¥
```bash
# è¿è¡Œç®€åŒ–æµ‹è¯•ï¼ˆä¸éœ€è¦PyTorchï¼‰
python3 test_cuda_simple.py

# è¿è¡Œå®Œæ•´CUDAæµ‹è¯•ï¼ˆéœ€è¦PyTorchï¼‰
python3 test_cuda_training.py
```

### 2. åŸºç¡€è®­ç»ƒ
```bash
# æŸ¥çœ‹æ‰€æœ‰å¯ç”¨å‚æ•°
python3 train_cuda.py --help

# åŸºç¡€CUDAè®­ç»ƒ
python3 train_cuda.py \
    --data-dir data \
    --output-dir outputs/cuda_training \
    --epochs 50 \
    --batch-size 32 \
    --learning-rate 0.001

# è‡ªåŠ¨ä¼˜åŒ–æ‰¹æ¬¡å¤§å°
python3 train_cuda.py \
    --auto-batch-size \
    --use-mixed-precision \
    --epochs 100
```

### 3. é«˜çº§é…ç½®
```bash
# å¤§æ¨¡å‹è®­ç»ƒ
python3 train_cuda.py \
    --hidden-size 512 \
    --num-heads 16 \
    --num-encoder-layers 6 \
    --num-decoder-layers 6 \
    --batch-size 16 \
    --gradient-accumulation-steps 4 \
    --use-mixed-precision

# æ¢å¤è®­ç»ƒ
python3 train_cuda.py \
    --resume outputs/cuda_training/cuda_checkpoint_epoch_20.pth \
    --epochs 100
```

## ğŸ”§ é…ç½®å‚æ•°è¯¦è§£

### æ¨¡å‹å‚æ•°
- `--hidden-size`: éšè—å±‚å¤§å° (é»˜è®¤: 256)
- `--num-heads`: æ³¨æ„åŠ›å¤´æ•° (é»˜è®¤: 8)
- `--num-encoder-layers`: ç¼–ç å™¨å±‚æ•° (é»˜è®¤: 4)
- `--num-decoder-layers`: è§£ç å™¨å±‚æ•° (é»˜è®¤: 4)
- `--max-length`: æœ€å¤§åºåˆ—é•¿åº¦ (é»˜è®¤: 128)

### è®­ç»ƒå‚æ•°
- `--batch-size`: æ‰¹æ¬¡å¤§å° (é»˜è®¤: 32)
- `--learning-rate`: å­¦ä¹ ç‡ (é»˜è®¤: 0.001)
- `--epochs`: è®­ç»ƒè½®æ¬¡ (é»˜è®¤: 100)
- `--gradient-accumulation-steps`: æ¢¯åº¦ç´¯ç§¯æ­¥æ•° (é»˜è®¤: 1)

### CUDAå‚æ•°
- `--use-mixed-precision`: å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒ
- `--gpu-memory-fraction`: GPUå†…å­˜ä½¿ç”¨æ¯”ä¾‹ (é»˜è®¤: 0.8)
- `--auto-batch-size`: è‡ªåŠ¨ä¼˜åŒ–æ‰¹æ¬¡å¤§å°

### ä¼˜åŒ–å‚æ•°
- `--weight-decay`: æƒé‡è¡°å‡ (é»˜è®¤: 1e-5)
- `--max-grad-norm`: æ¢¯åº¦è£å‰ªé˜ˆå€¼ (é»˜è®¤: 1.0)
- `--label-smoothing`: æ ‡ç­¾å¹³æ»‘ (é»˜è®¤: 0.1)

## ğŸ“Š æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ‰¹æ¬¡å¤§å°ä¼˜åŒ–
```bash
# è®©ç³»ç»Ÿè‡ªåŠ¨é€‰æ‹©æœ€ä¼˜æ‰¹æ¬¡å¤§å°
python3 train_cuda.py --auto-batch-size

# æ‰‹åŠ¨è°ƒæ•´ï¼ˆæ ¹æ®GPUå†…å­˜ï¼‰
# 8GB GPU: batch-size 16-32
# 16GB GPU: batch-size 32-64
# 24GB GPU: batch-size 64-128
```

### 2. æ··åˆç²¾åº¦è®­ç»ƒ
```bash
# å¯ç”¨æ··åˆç²¾åº¦ï¼ˆæ¨èç”¨äºV100/A100ç­‰ç°ä»£GPUï¼‰
python3 train_cuda.py --use-mixed-precision

# æ£€æŸ¥GPUæ˜¯å¦æ”¯æŒæ··åˆç²¾åº¦
python3 -c "
import torch
if torch.cuda.is_available():
    props = torch.cuda.get_device_properties(0)
    print(f'è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}')
    print(f'æ”¯æŒæ··åˆç²¾åº¦: {props.major >= 7}')
"
```

### 3. æ¢¯åº¦ç´¯ç§¯
```bash
# æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡è®­ç»ƒï¼ˆç­‰æ•ˆbatch_size = 32 * 4 = 128ï¼‰
python3 train_cuda.py \
    --batch-size 32 \
    --gradient-accumulation-steps 4
```

### 4. å†…å­˜ä¼˜åŒ–
```bash
# é™ä½GPUå†…å­˜ä½¿ç”¨
python3 train_cuda.py \
    --gpu-memory-fraction 0.7 \
    --batch-size 16

# ä½¿ç”¨æ›´å°çš„æ¨¡å‹
python3 train_cuda.py \
    --hidden-size 128 \
    --num-heads 4 \
    --num-encoder-layers 3
```

## ğŸ³ Dockeréƒ¨ç½²

### 1. æ„å»ºCUDAé•œåƒ
```bash
# æ„å»ºé•œåƒ
docker build -f Dockerfile.cuda -t logic-training-cuda:latest .

# éªŒè¯é•œåƒ
docker run --gpus all --rm logic-training-cuda:latest \
    python3 -c "import torch; print(f'CUDA: {torch.cuda.is_available()}')"
```

### 2. è¿è¡ŒCUDAå®¹å™¨
```bash
# åŸºç¡€è¿è¡Œ
docker run --gpus all -it --rm \
    -v $(pwd)/data:/app/data:ro \
    -v $(pwd)/outputs:/app/outputs \
    logic-training-cuda:latest \
    python3 train_cuda.py --epochs 50

# åå°è¿è¡Œ
docker run --gpus all -d \
    --name cuda-training \
    -v $(pwd)/data:/app/data:ro \
    -v $(pwd)/outputs:/app/outputs \
    logic-training-cuda:latest \
    python3 train_cuda.py --epochs 100 --batch-size 64

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
docker logs -f cuda-training
```

## ğŸ“ˆ ç›‘æ§å’Œè°ƒè¯•

### 1. GPUç›‘æ§
```bash
# å®æ—¶ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# æˆ–ä½¿ç”¨nvtopï¼ˆå¦‚æœå®‰è£…ï¼‰
nvtop
```

### 2. è®­ç»ƒç›‘æ§
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f outputs/cuda_training/training.log

# æŸ¥çœ‹TensorBoardï¼ˆå¦‚æœå¯ç”¨ï¼‰
tensorboard --logdir outputs/cuda_training/tensorboard
```

### 3. å†…å­˜è°ƒè¯•
```python
# åœ¨Pythonä¸­ç›‘æ§GPUå†…å­˜
import torch
print(f"å·²åˆ†é…: {torch.cuda.memory_allocated()/1e9:.2f}GB")
print(f"å·²ç¼“å­˜: {torch.cuda.memory_reserved()/1e9:.2f}GB")
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. CUDAä¸å¯ç”¨
```bash
# æ£€æŸ¥NVIDIAé©±åŠ¨
nvidia-smi

# æ£€æŸ¥CUDAå®‰è£…
nvcc --version

# é‡æ–°å®‰è£…PyTorch CUDAç‰ˆæœ¬
pip uninstall torch torchvision torchaudio
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

#### 2. GPUå†…å­˜ä¸è¶³
```bash
# å‡å°æ‰¹æ¬¡å¤§å°
python3 train_cuda.py --batch-size 8

# å¯ç”¨æ¢¯åº¦ç´¯ç§¯
python3 train_cuda.py --batch-size 8 --gradient-accumulation-steps 4

# å‡å°æ¨¡å‹å¤§å°
python3 train_cuda.py --hidden-size 128 --num-heads 4
```

#### 3. è®­ç»ƒé€Ÿåº¦æ…¢
```bash
# å¯ç”¨æ··åˆç²¾åº¦
python3 train_cuda.py --use-mixed-precision

# å¢å¤§æ‰¹æ¬¡å¤§å°
python3 train_cuda.py --auto-batch-size

# æ£€æŸ¥æ•°æ®åŠ è½½ç“¶é¢ˆ
python3 train_cuda.py --log-frequency 10
```

#### 4. æ¨¡å‹ä¸æ”¶æ•›
```bash
# è°ƒæ•´å­¦ä¹ ç‡
python3 train_cuda.py --learning-rate 0.0005

# å¢åŠ æ¨¡å‹å®¹é‡
python3 train_cuda.py --hidden-size 512 --num-heads 16

# å‡å°‘æ­£åˆ™åŒ–
python3 train_cuda.py --weight-decay 1e-6 --label-smoothing 0.05
```

## ğŸ“Š æ€§èƒ½åŸºå‡†

### é¢„æœŸæ€§èƒ½æå‡
- **GPU vs CPU**: 5-20x åŠ é€Ÿ
- **æ··åˆç²¾åº¦**: 1.5-2x é¢å¤–åŠ é€Ÿ
- **æ‰¹æ¬¡ä¼˜åŒ–**: 10-30% æ€§èƒ½æå‡

### ä¸åŒGPUæ€§èƒ½å‚è€ƒ
| GPUå‹å· | æ¨èæ‰¹æ¬¡å¤§å° | é¢„æœŸè®­ç»ƒæ—¶é—´ |
|---------|-------------|-------------|
| GTX 1080 Ti | 16-32 | åŸºå‡† |
| RTX 3080 | 32-64 | 0.6x |
| RTX 4090 | 64-128 | 0.4x |
| V100 | 32-64 | 0.5x |
| A100 | 64-128 | 0.3x |

## ğŸ¯ æœ€ä½³å®è·µ

1. **å¼€å§‹è®­ç»ƒå‰**:
   - è¿è¡Œ `test_cuda_simple.py` æ£€æŸ¥ç¯å¢ƒ
   - ä½¿ç”¨ `--auto-batch-size` æ‰¾åˆ°æœ€ä¼˜æ‰¹æ¬¡å¤§å°
   - å¯ç”¨æ··åˆç²¾åº¦è®­ç»ƒï¼ˆå¦‚æœGPUæ”¯æŒï¼‰

2. **è®­ç»ƒè¿‡ç¨‹ä¸­**:
   - ç›‘æ§GPUå†…å­˜ä½¿ç”¨ç‡
   - å®šæœŸä¿å­˜æ£€æŸ¥ç‚¹
   - è§‚å¯Ÿè®­ç»ƒæŸå¤±æ›²çº¿

3. **æ€§èƒ½è°ƒä¼˜**:
   - æ ¹æ®GPUå†…å­˜è°ƒæ•´æ‰¹æ¬¡å¤§å°
   - ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯æ¨¡æ‹Ÿå¤§æ‰¹æ¬¡
   - é€‚å½“è°ƒæ•´æ¨¡å‹å¤§å°

---

**ğŸ‰ ç°åœ¨æ‚¨å¯ä»¥äº«å—GPUåŠ é€Ÿçš„é«˜æ€§èƒ½è®­ç»ƒäº†ï¼**
