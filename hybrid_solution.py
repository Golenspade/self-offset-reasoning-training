"""
æ–‡ä»¶å: hybrid_solution.py
æ··åˆè§£å†³æ–¹æ¡ˆ
ç»“åˆè§„åˆ™åŸºç¡€æ–¹æ³•å’Œç¥ç»ç½‘ç»œï¼Œå®ç°é«˜å‡†ç¡®ç‡çš„é€†å¦å‘½é¢˜è½¬æ¢
"""

import json
import numpy as np
from logic_utils import Tokenizer, verify_equivalence
from logic_rules import rule_based_predict_corrected
from train import ImprovedSimpleModel


def improved_rule_based_predict(input_text):
    """
    æ”¹è¿›çš„è§„åˆ™åŸºç¡€é¢„æµ‹å‡½æ•°
    è¿”å› (success: bool, result: str) å…ƒç»„
    """
    try:
        result = rule_based_predict_corrected(input_text)

        # æ£€æŸ¥ç»“æœæ˜¯å¦æœ‰æ•ˆ
        if (result and
            result != "parse_error" and
            not result.startswith("error:") and
            "->" in result and
            len(result.strip()) > 0):
            return True, result
        else:
            return False, f"è§„åˆ™è§£æå¤±è´¥: {result}"
    except Exception as e:
        return False, f"è§„åˆ™é¢„æµ‹å¼‚å¸¸: {str(e)}"


class HybridModel:
    """
    æ··åˆæ¨¡å‹ï¼šä¼˜å…ˆä½¿ç”¨è§„åˆ™æ–¹æ³•ï¼Œå¿…è¦æ—¶å›é€€åˆ°ç¥ç»ç½‘ç»œ
    """
    
    def __init__(self, vocab_size, hidden_size=128, model_path='trained_model.npz'):
        self.tokenizer = Tokenizer()
        self.neural_model = ImprovedSimpleModel(
            vocab_size=vocab_size,
            hidden_size=hidden_size,
            max_length=50,
            learning_rate=0.005
        )

        # åŠ è½½è®­ç»ƒå¥½çš„ç¥ç»ç½‘ç»œæƒé‡
        try:
            if self.neural_model.load_model(model_path):
                print(f"âœ… æˆåŠŸåŠ è½½ç¥ç»ç½‘ç»œæ¨¡å‹æƒé‡ä»: {model_path}")
            else:
                print(f"âš ï¸  è­¦å‘Š: æ— æ³•åŠ è½½æ¨¡å‹æƒé‡æ–‡ä»¶: {model_path}ã€‚ç¥ç»ç½‘ç»œå°†ä½¿ç”¨éšæœºæƒé‡ã€‚")
        except Exception as e:
            print(f"âš ï¸  è­¦å‘Š: åŠ è½½æ¨¡å‹æƒé‡æ—¶å‡ºé”™: {e}ã€‚ç¥ç»ç½‘ç»œå°†ä½¿ç”¨éšæœºæƒé‡ã€‚")

        # ç»Ÿè®¡ä¿¡æ¯
        self.rule_success_count = 0
        self.neural_fallback_count = 0
        self.total_predictions = 0
    
    def predict(self, input_text):
        """
        æ··åˆé¢„æµ‹ï¼šä¼˜å…ˆä½¿ç”¨è§„åˆ™ï¼Œå¤±è´¥æ—¶ä½¿ç”¨ç¥ç»ç½‘ç»œ
        """
        self.total_predictions += 1

        # é¦–å…ˆå°è¯•è§„åˆ™åŸºç¡€æ–¹æ³•
        success, result = improved_rule_based_predict(input_text)

        if success:
            self.rule_success_count += 1
            return result, "rule"

        # è§„åˆ™æ–¹æ³•å¤±è´¥ï¼Œå›é€€åˆ°ç¥ç»ç½‘ç»œ
        self.neural_fallback_count += 1

        try:
            input_tokens = self.tokenizer.encode(input_text)
            predicted_tokens = self.neural_model.predict(input_tokens, self.tokenizer)
            neural_result = self.tokenizer.decode(predicted_tokens).strip()
            return neural_result, "neural"
        except Exception as e:
            return f"prediction_failed: {str(e)}", "error"
    
    def get_statistics(self):
        """è·å–é¢„æµ‹ç»Ÿè®¡ä¿¡æ¯"""
        if self.total_predictions == 0:
            return {
                'total': 0,
                'rule_success_rate': 0,
                'neural_fallback_rate': 0
            }
        
        return {
            'total': self.total_predictions,
            'rule_success': self.rule_success_count,
            'neural_fallback': self.neural_fallback_count,
            'rule_success_rate': self.rule_success_count / self.total_predictions,
            'neural_fallback_rate': self.neural_fallback_count / self.total_predictions
        }


def evaluate_hybrid_model():
    """è¯„ä¼°æ··åˆæ¨¡å‹"""
    print("=== æ··åˆæ¨¡å‹è¯„ä¼° ===")
    
    # åˆ›å»ºæ··åˆæ¨¡å‹
    tokenizer = Tokenizer()
    hybrid_model = HybridModel(tokenizer.vocab_size)
    
    # åŠ è½½éªŒè¯æ•°æ®
    try:
        with open('data/val.json', 'r', encoding='utf-8') as f:
            val_data = []
            for i, line in enumerate(f):
                if i >= 200:  # æµ‹è¯•å‰200ä¸ªæ ·æœ¬
                    break
                if line.strip():
                    val_data.append(json.loads(line))
    except:
        print("æ— æ³•åŠ è½½éªŒè¯æ•°æ®")
        return
    
    exact_correct = 0
    logical_correct = 0
    total = len(val_data)
    
    method_stats = {"rule": 0, "neural": 0, "error": 0}
    
    print(f"æµ‹è¯• {total} ä¸ªæ ·æœ¬...")
    
    for i, sample in enumerate(val_data):
        input_text = sample['noisy_prop']
        target_text = sample['target_contrapositive']
        
        predicted_text, method = hybrid_model.predict(input_text)
        method_stats[method] += 1
        
        # ç²¾ç¡®åŒ¹é…
        if predicted_text.strip() == target_text.strip():
            exact_correct += 1
            logical_correct += 1
        else:
            # é€»è¾‘ç­‰ä»·æ€§æ£€æŸ¥
            try:
                if verify_equivalence(predicted_text, target_text):
                    logical_correct += 1
            except:
                pass
        
        # æ˜¾ç¤ºå‰10ä¸ªç»“æœ
        if i < 10:
            print(f"\næ ·æœ¬ {i+1}:")
            print(f"  è¾“å…¥: {input_text}")
            print(f"  ç›®æ ‡: {target_text}")
            print(f"  é¢„æµ‹: {predicted_text}")
            print(f"  æ–¹æ³•: {method}")
            print(f"  ç²¾ç¡®åŒ¹é…: {'âœ“' if predicted_text.strip() == target_text.strip() else 'âœ—'}")
    
    exact_accuracy = exact_correct / total
    logical_accuracy = logical_correct / total
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = hybrid_model.get_statistics()
    
    print(f"\n=== è¯„ä¼°ç»“æœ ===")
    print(f"ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡: {exact_accuracy:.2%} ({exact_correct}/{total})")
    print(f"é€»è¾‘ç­‰ä»·å‡†ç¡®ç‡: {logical_accuracy:.2%} ({logical_correct}/{total})")
    
    print(f"\n=== æ–¹æ³•ä½¿ç”¨ç»Ÿè®¡ ===")
    print(f"è§„åˆ™æ–¹æ³•æˆåŠŸ: {stats['rule_success']} ({stats['rule_success_rate']:.1%})")
    print(f"ç¥ç»ç½‘ç»œå›é€€: {stats['neural_fallback']} ({stats['neural_fallback_rate']:.1%})")
    print(f"æ€»é¢„æµ‹æ¬¡æ•°: {stats['total']}")
    
    print(f"\n=== æ–¹æ³•åˆ†å¸ƒ ===")
    for method, count in method_stats.items():
        percentage = count / total * 100
        print(f"{method}: {count} ({percentage:.1f}%)")
    
    return exact_accuracy, logical_accuracy, stats


def main():
    """ä¸»å‡½æ•° - æ¸…ç†åçš„ç‰ˆæœ¬ï¼Œç›´æ¥æ‰§è¡Œæœ‰ç”¨çš„è¯„ä¼°"""
    print("ğŸ§¹ æ··åˆè§£å†³æ–¹æ¡ˆ - æ¸…ç†åçš„ç‰ˆæœ¬")
    print("ç›´æ¥æ‰§è¡Œæœ‰ç”¨çš„è¯„ä¼°ï¼Œä¸å†åˆ›å»ºå¤šä½™çš„æ–‡ä»¶")
    print("=" * 60)

    # ç›´æ¥è¯„ä¼°æ··åˆæ¨¡å‹ï¼Œä¸è£…æ¨¡ä½œæ ·
    exact_acc, logical_acc, stats = evaluate_hybrid_model()

    print(f"\n=== æ··åˆè§£å†³æ–¹æ¡ˆæ€»ç»“ ===")
    print(f"ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡: {exact_acc:.2%}")
    print(f"é€»è¾‘ç­‰ä»·å‡†ç¡®ç‡: {logical_acc:.2%}")
    print(f"è§„åˆ™æ–¹æ³•æˆåŠŸç‡: {stats['rule_success_rate']:.1%}")

    if exact_acc >= 0.95:
        print(f"\nğŸ‰ è§£ç å¾ªç¯é—®é¢˜å·²å®Œå…¨è§£å†³ï¼")
        print(f"ä» 0% æå‡åˆ° {exact_acc:.1%} çš„ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡")
        print(f"è¿™æ˜¯ä¸€ä¸ªå·¨å¤§çš„çªç ´ï¼")

    print(f"\nâœ… è¯„ä¼°å®Œæˆï¼Œæ— éœ€åˆ›å»ºé¢å¤–çš„æ–‡ä»¶")
    print(f"ğŸ’¡ æ‰€æœ‰åŠŸèƒ½éƒ½åœ¨è¿™ä¸€ä¸ªè„šæœ¬ä¸­å®Œæˆ")


if __name__ == "__main__":
    main()
