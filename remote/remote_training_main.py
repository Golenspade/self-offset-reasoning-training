"""
æ–‡ä»¶å: remote_training_main.py
è¿œç¨‹è®­ç»ƒä¸»ç¨‹åº
æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒå’Œäº‘ç«¯éƒ¨ç½²
"""
import os
import sys
import json
import logging
import signal
import traceback
from pathlib import Path
from datetime import datetime
from typing import Optional

# è®¡ç®—é¡¹ç›®æ ¹ç›®å½•ï¼ˆremote/ çš„ä¸Šä¸€çº§ï¼‰å¹¶æ·»åŠ åˆ° Python è·¯å¾„
PROJECT_ROOT = Path(__file__).resolve().parents[1]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT))
if str(PROJECT_ROOT / "src") not in sys.path:
    sys.path.insert(0, str(PROJECT_ROOT / "src"))

from remote.remote_training_config import RemoteTrainingConfig
from scripts.breakthrough_training_system_refactored import BreakthroughTrainingSystem


class RemoteTrainingManager:
    """è¿œç¨‹è®­ç»ƒç®¡ç†å™¨"""
    
    def __init__(self, config_file: Optional[str] = None):
        """åˆå§‹åŒ–è¿œç¨‹è®­ç»ƒç®¡ç†å™¨"""
        self.config = RemoteTrainingConfig(config_file)
        self.training_system = None
        self.logger = None
        self.start_time = None
        
        # è®¾ç½®ä¿¡å·å¤„ç†
        signal.signal(signal.SIGINT, self._signal_handler)
        signal.signal(signal.SIGTERM, self._signal_handler)
    
    def setup_logging(self):
        """è®¾ç½®æ—¥å¿—ç³»ç»Ÿ"""
        # åˆ›å»ºæ—¥å¿—ç›®å½•
        log_dir = os.path.join(self.config.remote_output_path, 'logs')
        os.makedirs(log_dir, exist_ok=True)
        
        # è®¾ç½®æ—¥å¿—æ ¼å¼
        log_format = '%(asctime)s - %(name)s - %(levelname)s - %(message)s'
        
        # é…ç½®æ—¥å¿—å¤„ç†å™¨
        handlers = []
        
        # æ–‡ä»¶å¤„ç†å™¨
        log_file = os.path.join(log_dir, f'training_{datetime.now().strftime("%Y%m%d_%H%M%S")}.log')
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        file_handler.setFormatter(logging.Formatter(log_format))
        handlers.append(file_handler)
        
        # æ§åˆ¶å°å¤„ç†å™¨
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO if not self.config.debug_mode else logging.DEBUG)
        console_handler.setFormatter(logging.Formatter(log_format))
        handlers.append(console_handler)
        
        # é…ç½®æ ¹æ—¥å¿—å™¨
        logging.basicConfig(
            level=logging.DEBUG if self.config.debug_mode else logging.INFO,
            format=log_format,
            handlers=handlers
        )
        
        self.logger = logging.getLogger(__name__)
        self.logger.info("ğŸ“ æ—¥å¿—ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        self.logger.info(f"ğŸ“ æ—¥å¿—æ–‡ä»¶: {log_file}")
    
    def setup_monitoring(self):
        """è®¾ç½®ç›‘æ§ç³»ç»Ÿ"""
        try:
            # åˆå§‹åŒ–Weights & Biases
            if self.config.enable_wandb:
                import wandb
                wandb.init(
                    project=self.config.wandb_project,
                    entity=self.config.wandb_entity,
                    config=self.config.get_training_config(),
                    name=f"remote_training_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
                )
                self.logger.info("ğŸ“Š Weights & Biases ç›‘æ§å·²å¯ç”¨")
            
        except Exception as e:
            self.logger.warning(f"âš ï¸ ç›‘æ§ç³»ç»Ÿè®¾ç½®å¤±è´¥: {e}")
    
    def validate_environment(self):
        """éªŒè¯è¿œç¨‹ç¯å¢ƒ"""
        self.logger.info("ğŸ” éªŒè¯è¿œç¨‹ç¯å¢ƒ...")
        
        # æ£€æŸ¥å¿…è¦ç›®å½•
        self.config.create_directories()
        
        # æ£€æŸ¥æ•°æ®æ–‡ä»¶
        paths = self.config.get_full_paths()
        
        if not os.path.exists(paths['train_data']):
            self.logger.error(f"âŒ è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {paths['train_data']}")
            raise FileNotFoundError(f"è®­ç»ƒæ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {paths['train_data']}")
        
        if not os.path.exists(paths['val_data']):
            self.logger.error(f"âŒ éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {paths['val_data']}")
            raise FileNotFoundError(f"éªŒè¯æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {paths['val_data']}")
        
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        try:
            import torch
            if torch.cuda.is_available():
                gpu_count = torch.cuda.device_count()
                self.logger.info(f"ğŸ® æ£€æµ‹åˆ° {gpu_count} ä¸ªGPU")
                for i in range(gpu_count):
                    gpu_name = torch.cuda.get_device_name(i)
                    gpu_memory = torch.cuda.get_device_properties(i).total_memory / 1024**3
                    self.logger.info(f"  GPU {i}: {gpu_name} ({gpu_memory:.1f}GB)")
            else:
                self.logger.warning("âš ï¸ æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒ")
        except ImportError:
            self.logger.warning("âš ï¸ PyTorchæœªå®‰è£…ï¼Œæ— æ³•æ£€æµ‹GPU")
        
        self.logger.info("âœ… ç¯å¢ƒéªŒè¯å®Œæˆ")
    
    def initialize_training_system(self):
        """åˆå§‹åŒ–è®­ç»ƒç³»ç»Ÿ"""
        self.logger.info("ğŸš€ åˆå§‹åŒ–è®­ç»ƒç³»ç»Ÿ...")
        
        try:
            # åˆ›å»ºè®­ç»ƒé…ç½®
            training_config = self.config.get_training_config()
            training_config.update(self.config.get_model_config())
            training_config['remote_config'] = self.config
            
            # åˆå§‹åŒ–è®­ç»ƒç³»ç»Ÿ
            self.training_system = BreakthroughTrainingSystem(training_config)
            
            self.logger.info("âœ… è®­ç»ƒç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def run_training(self):
        """æ‰§è¡Œè®­ç»ƒ"""
        self.logger.info("ğŸ¯ å¼€å§‹è¿œç¨‹è®­ç»ƒ...")
        self.start_time = datetime.now()
        
        try:
            # å¦‚æœæ˜¯å¹²è¿è¡Œæ¨¡å¼
            if self.config.dry_run:
                self.logger.info("ğŸ§ª å¹²è¿è¡Œæ¨¡å¼ï¼Œè·³è¿‡å®é™…è®­ç»ƒ")
                self._simulate_training()
                return
            
            # æ‰§è¡Œå®é™…è®­ç»ƒ
            if hasattr(self.training_system, 'run_remote_training'):
                # ä½¿ç”¨ä¸“é—¨çš„è¿œç¨‹è®­ç»ƒæ–¹æ³•
                results = self.training_system.run_remote_training(self.config)
            else:
                # ä½¿ç”¨æ ‡å‡†è®­ç»ƒæ–¹æ³•
                results = self.training_system.run_full_training()
            
            # è®°å½•è®­ç»ƒç»“æœ
            self._log_training_results(results)
            
            self.logger.info("ğŸ‰ è¿œç¨‹è®­ç»ƒå®Œæˆï¼")
            
        except Exception as e:
            self.logger.error(f"âŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            self.logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
            raise
        
        finally:
            # è®¡ç®—è®­ç»ƒæ—¶é—´
            if self.start_time:
                duration = datetime.now() - self.start_time
                self.logger.info(f"â±ï¸ æ€»è®­ç»ƒæ—¶é—´: {duration}")
    
    def _simulate_training(self):
        """æ¨¡æ‹Ÿè®­ç»ƒï¼ˆç”¨äºæµ‹è¯•ï¼‰"""
        import time
        
        self.logger.info("ğŸ§ª æ¨¡æ‹Ÿè®­ç»ƒå¼€å§‹...")
        
        for epoch in range(min(5, self.config.epochs)):
            self.logger.info(f"æ¨¡æ‹Ÿè®­ç»ƒ Epoch {epoch+1}/{min(5, self.config.epochs)}")
            time.sleep(2)  # æ¨¡æ‹Ÿè®­ç»ƒæ—¶é—´
            
            # æ¨¡æ‹ŸæŒ‡æ ‡
            fake_metrics = {
                'epoch': epoch + 1,
                'train_loss': 0.5 - epoch * 0.05,
                'val_loss': 0.6 - epoch * 0.04,
                'accuracy': 0.7 + epoch * 0.05
            }
            
            self.logger.info(f"æ¨¡æ‹ŸæŒ‡æ ‡: {fake_metrics}")
        
        self.logger.info("ğŸ§ª æ¨¡æ‹Ÿè®­ç»ƒå®Œæˆ")
    
    def _log_training_results(self, results):
        """è®°å½•è®­ç»ƒç»“æœ"""
        if results:
            self.logger.info("ğŸ“Š è®­ç»ƒç»“æœ:")
            for key, value in results.items():
                self.logger.info(f"  {key}: {value}")
            
            # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
            results_file = os.path.join(self.config.remote_output_path, 'training_results.json')
            with open(results_file, 'w', encoding='utf-8') as f:
                json.dump(results, f, indent=2, ensure_ascii=False)
            
            self.logger.info(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {results_file}")
    
    def _signal_handler(self, signum, frame):
        """ä¿¡å·å¤„ç†å™¨"""
        self.logger.info(f"ğŸ›‘ æ¥æ”¶åˆ°ä¿¡å· {signum}ï¼Œæ­£åœ¨ä¼˜é›…å…³é—­...")
        
        # ä¿å­˜å½“å‰çŠ¶æ€
        if self.training_system:
            try:
                checkpoint_path = os.path.join(
                    self.config.remote_checkpoint_path, 
                    'emergency_checkpoint.npz'
                )
                # è¿™é‡Œåº”è¯¥è°ƒç”¨è®­ç»ƒç³»ç»Ÿçš„ä¿å­˜æ–¹æ³•
                self.logger.info(f"ğŸ’¾ ç´§æ€¥ä¿å­˜æ£€æŸ¥ç‚¹åˆ°: {checkpoint_path}")
            except Exception as e:
                self.logger.error(f"âŒ ç´§æ€¥ä¿å­˜å¤±è´¥: {e}")
        
        sys.exit(0)
    
    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        self.logger.info("ğŸ§¹ æ¸…ç†èµ„æº...")
        
        try:
            # å…³é—­ç›‘æ§
            if self.config.enable_wandb:
                import wandb
                wandb.finish()
            
            # å…¶ä»–æ¸…ç†å·¥ä½œ
            self.logger.info("âœ… èµ„æºæ¸…ç†å®Œæˆ")
            
        except Exception as e:
            self.logger.error(f"âš ï¸ èµ„æºæ¸…ç†æ—¶å‘ç”Ÿé”™è¯¯: {e}")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¯åŠ¨è¿œç¨‹è®­ç»ƒç³»ç»Ÿ")
    print("=" * 60)
    
    # è·å–é…ç½®æ–‡ä»¶è·¯å¾„
    config_file = os.getenv('CONFIG_FILE', None)
    if config_file and not os.path.exists(config_file):
        print(f"âš ï¸ é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {config_file}")
        config_file = None
    
    try:
        # åˆ›å»ºè®­ç»ƒç®¡ç†å™¨
        manager = RemoteTrainingManager(config_file)
        
        # è®¾ç½®æ—¥å¿—
        manager.setup_logging()
        
        # æ‰“å°é…ç½®ä¿¡æ¯
        manager.logger.info(str(manager.config))
        
        # è®¾ç½®ç›‘æ§
        manager.setup_monitoring()
        
        # éªŒè¯ç¯å¢ƒ
        manager.validate_environment()
        
        # åˆå§‹åŒ–è®­ç»ƒç³»ç»Ÿ
        manager.initialize_training_system()
        
        # æ‰§è¡Œè®­ç»ƒ
        manager.run_training()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ ç”¨æˆ·ä¸­æ–­è®­ç»ƒ")
        sys.exit(0)
        
    except Exception as e:
        print(f"âŒ è¿œç¨‹è®­ç»ƒå¤±è´¥: {e}")
        print(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        sys.exit(1)
        
    finally:
        # æ¸…ç†èµ„æº
        if 'manager' in locals():
            manager.cleanup()
    
    print("ğŸ‰ è¿œç¨‹è®­ç»ƒç³»ç»Ÿé€€å‡º")


if __name__ == "__main__":
    main()
