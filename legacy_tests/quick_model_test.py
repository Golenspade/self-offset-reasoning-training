"""
å¿«é€Ÿæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹åœ¨è®­ç»ƒé›†ä¸Šçš„è¡¨ç°
"""

import sys
import os
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / 'src'))

from logic_transformer.data_utils import Tokenizer, load_dataset
from logic_transformer.models.base_model import ImprovedSimpleModel


def quick_test_model():
    """å¿«é€Ÿæµ‹è¯•æ¨¡å‹è¡¨ç°"""
    print("ğŸ§ª å¿«é€Ÿæµ‹è¯•è®­ç»ƒå¥½çš„æ¨¡å‹...")
    
    # åˆå§‹åŒ–tokenizer
    tokenizer = Tokenizer()
    
    # æµ‹è¯•ä¸åŒçš„æ¨¡å‹
    models_to_test = [
        {
            'name': 'Level 1 é²æ£’ç‰ˆ',
            'model_path': 'outputs/trained_models/robust_model_Level_1_é²æ£’ç‰ˆ.npz',
            'data_path': 'data/train_level_1_é²æ£’ç‰ˆ.json'
        },
        {
            'name': 'Level 3 é²æ£’ç‰ˆ', 
            'model_path': 'outputs/trained_models/robust_model_Level_3_é²æ£’ç‰ˆ.npz',
            'data_path': 'data/train_level_3_é²æ£’ç‰ˆ.json'
        }
    ]
    
    for model_config in models_to_test:
        print(f"\nğŸ“Š æµ‹è¯• {model_config['name']}")
        print("-" * 40)
        
        # åŠ è½½æ¨¡å‹
        model = ImprovedSimpleModel(
            vocab_size=tokenizer.vocab_size,
            hidden_size=128,
            max_length=50,
            learning_rate=0.003
        )
        
        if not model.load_model(model_config['model_path']):
            print(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹: {model_config['model_path']}")
            continue
        
        # åŠ è½½æ•°æ®
        data = load_dataset(model_config['data_path'], tokenizer, 10)  # åªæµ‹è¯•10ä¸ªæ ·æœ¬
        
        if not data:
            print(f"âŒ æ— æ³•åŠ è½½æ•°æ®: {model_config['data_path']}")
            continue
        
        print(f"âœ… æ¨¡å‹å’Œæ•°æ®åŠ è½½æˆåŠŸ")
        
        # æµ‹è¯•å‡ ä¸ªæ ·æœ¬
        for i, sample in enumerate(data[:5]):
            try:
                predicted_tokens = model.predict(sample['input'], tokenizer)
                predicted_text = tokenizer.decode(predicted_tokens).strip()
                target_text = sample['target_text'].strip()
                
                print(f"\n  æ ·æœ¬ {i+1}:")
                print(f"    è¾“å…¥: {sample['input_text']}")
                print(f"    ç›®æ ‡: {target_text}")
                print(f"    é¢„æµ‹: {predicted_text}")
                
                # ç®€å•åˆ†æ
                if predicted_text == target_text:
                    print(f"    ç»“æœ: âœ… å®Œå…¨åŒ¹é…")
                elif '->' in predicted_text and len(predicted_text) > 5:
                    print(f"    ç»“æœ: ğŸ”„ æ ¼å¼æ­£ç¡®ä½†å†…å®¹ä¸åŒ")
                elif predicted_text.startswith('-> -> ->'):
                    print(f"    ç»“æœ: ğŸš¨ é™·å…¥å¾ªç¯æ¨¡å¼")
                else:
                    print(f"    ç»“æœ: âŒ æ ¼å¼é”™è¯¯")
                    
            except Exception as e:
                print(f"    ç»“æœ: âŒ é¢„æµ‹å‡ºé”™: {e}")
        
        print(f"\nğŸ“ˆ {model_config['name']} æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    quick_test_model()
