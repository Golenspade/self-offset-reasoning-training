"""
äº¤å‰è¯„ä¼°æµ‹è¯•ï¼šéªŒè¯Level 3æ¨¡å‹æ˜¯å¦çœŸçš„å­¦ä¼šäº†é€»è¾‘æ¨ç†
"""

import sys
import os
from pathlib import Path

# æ·»åŠ srcç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root / 'src'))

from logic_transformer.data_utils import Tokenizer, load_dataset
from logic_transformer.models.base_model import ImprovedSimpleModel


def load_trained_model(model_path, tokenizer):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    model = ImprovedSimpleModel(
        vocab_size=tokenizer.vocab_size,
        hidden_size=128,
        max_length=50,
        learning_rate=0.005
    )
    
    if model.load_model(model_path):
        print(f"âœ… æˆåŠŸåŠ è½½æ¨¡å‹: {model_path}")
        return model
    else:
        print(f"âŒ æ— æ³•åŠ è½½æ¨¡å‹: {model_path}")
        return None


def evaluate_cross_performance(model, data, tokenizer, data_name):
    """è¯„ä¼°æ¨¡å‹åœ¨ä¸åŒæ•°æ®é›†ä¸Šçš„æ€§èƒ½"""
    if not data:
        return 0, 0
    
    correct_exact = 0
    correct_logical = 0
    total = len(data)
    
    print(f"\nğŸ§ª åœ¨{data_name}ä¸Šè¯„ä¼°æ¨¡å‹æ€§èƒ½...")
    print(f"æ ·æœ¬æ•°é‡: {total}")
    
    # æ˜¾ç¤ºå‰å‡ ä¸ªé¢„æµ‹ç¤ºä¾‹
    print(f"\nğŸ“ é¢„æµ‹ç¤ºä¾‹:")
    for i, sample in enumerate(data[:5]):
        try:
            predicted_tokens = model.predict(sample['input'], tokenizer)
            predicted_text = tokenizer.decode(predicted_tokens).strip()
            target_text = sample['target_text'].strip()
            
            print(f"\n  æ ·æœ¬ {i+1}:")
            print(f"    è¾“å…¥: {sample['input_text']}")
            print(f"    ç›®æ ‡: {target_text}")
            print(f"    é¢„æµ‹: {predicted_text}")
            print(f"    åŒ¹é…: {'âœ“' if predicted_text == target_text else 'âœ—'}")
            
        except Exception as e:
            print(f"    é¢„æµ‹å‡ºé”™: {e}")
    
    # è®¡ç®—æ•´ä½“å‡†ç¡®ç‡
    for sample in data:
        try:
            predicted_tokens = model.predict(sample['input'], tokenizer)
            predicted_text = tokenizer.decode(predicted_tokens).strip()
            target_text = sample['target_text'].strip()
            
            # ç²¾ç¡®åŒ¹é…
            if predicted_text == target_text:
                correct_exact += 1
                correct_logical += 1
            else:
                # ç®€åŒ–çš„é€»è¾‘ç­‰ä»·æ£€æŸ¥
                if len(predicted_text) > 0 and '->' in predicted_text:
                    correct_logical += 1
        except:
            continue
    
    exact_acc = correct_exact / total if total > 0 else 0
    logical_acc = correct_logical / total if total > 0 else 0
    
    return exact_acc, logical_acc


def run_cross_evaluation():
    """è¿è¡Œäº¤å‰è¯„ä¼°å®éªŒ"""
    print("ğŸ”¬ Level 3æ¨¡å‹äº¤å‰è¯„ä¼°å®éªŒ")
    print("=" * 60)
    
    # åˆå§‹åŒ–tokenizer
    tokenizer = Tokenizer()
    
    # åŠ è½½Level 3è®­ç»ƒçš„æ¨¡å‹
    l3_model_path = "outputs/trained_models/model_Level_3_å¤æ‚ç»“æ„.npz"
    l3_model = load_trained_model(l3_model_path, tokenizer)
    
    if l3_model is None:
        print("âŒ æ— æ³•åŠ è½½Level 3æ¨¡å‹ï¼Œé€€å‡ºæµ‹è¯•")
        return
    
    # åŠ è½½ä¸åŒçº§åˆ«çš„éªŒè¯æ•°æ®
    datasets = {
        "Level 1 (ç®€å•å‘½é¢˜)": "data/val_L1_simple.json",
        "Level 2 (å¤šå™ªå£°)": "data/val_L2_multi_noise.json", 
        "Level 3 (å¤æ‚ç»“æ„)": "data/val_L3_complex.json"
    }
    
    results = {}
    
    for dataset_name, dataset_path in datasets.items():
        print(f"\n{'='*60}")
        print(f"ğŸ“Š è¯„ä¼° {dataset_name}")
        print(f"{'='*60}")
        
        # åŠ è½½æ•°æ®
        data = load_dataset(dataset_path, tokenizer, 100)  # é™åˆ¶100ä¸ªæ ·æœ¬
        
        if not data:
            print(f"âŒ æ— æ³•åŠ è½½æ•°æ®: {dataset_path}")
            continue
        
        # è¯„ä¼°æ€§èƒ½
        exact_acc, logical_acc = evaluate_cross_performance(l3_model, data, tokenizer, dataset_name)
        
        results[dataset_name] = {
            'exact_accuracy': exact_acc,
            'logical_accuracy': logical_acc,
            'sample_count': len(data)
        }
        
        print(f"\nğŸ“ˆ {dataset_name} ç»“æœ:")
        print(f"  ç²¾ç¡®åŒ¹é…å‡†ç¡®ç‡: {exact_acc:.2%}")
        print(f"  é€»è¾‘å‡†ç¡®ç‡: {logical_acc:.2%}")
    
    return results


def analyze_cross_evaluation_results(results):
    """åˆ†æäº¤å‰è¯„ä¼°ç»“æœ"""
    print(f"\nğŸ¯ äº¤å‰è¯„ä¼°ç»“æœåˆ†æ")
    print("=" * 60)
    
    if not results:
        print("âŒ æ²¡æœ‰å¯åˆ†æçš„ç»“æœ")
        return
    
    print(f"{'æ•°æ®é›†':<20} {'ç²¾ç¡®å‡†ç¡®ç‡':<12} {'é€»è¾‘å‡†ç¡®ç‡':<12} {'æ ·æœ¬æ•°':<8}")
    print("-" * 60)
    
    for dataset_name, result in results.items():
        print(f"{dataset_name:<20} {result['exact_accuracy']:<12.1%} "
              f"{result['logical_accuracy']:<12.1%} {result['sample_count']:<8}")
    
    # åˆ†æç»“è®º
    print(f"\nğŸ” åˆ†æç»“è®º:")
    
    l3_acc = results.get("Level 3 (å¤æ‚ç»“æ„)", {}).get('exact_accuracy', 0)
    l1_acc = results.get("Level 1 (ç®€å•å‘½é¢˜)", {}).get('exact_accuracy', 0)
    l2_acc = results.get("Level 2 (å¤šå™ªå£°)", {}).get('exact_accuracy', 0)
    
    if l3_acc > 0.8 and l1_acc < 0.1:
        print("ğŸš¨ **ç¡®è®¤ä½œå¼Šè¡Œä¸ºï¼**")
        print("   Level 3æ¨¡å‹åœ¨å¤æ‚æ•°æ®ä¸Šè¡¨ç°å®Œç¾ï¼Œä½†åœ¨ç®€å•æ•°æ®ä¸Šå®Œå…¨å¤±è´¥")
        print("   è¿™è¯æ˜æ¨¡å‹å­¦åˆ°çš„æ˜¯ç‰¹å®šäºLevel 3æ•°æ®çš„æ·å¾„ï¼Œè€Œéé€šç”¨é€»è¾‘")
        
    elif l3_acc > 0.8 and l1_acc > 0.3:
        print("âœ… **æ¨¡å‹å¯èƒ½å­¦åˆ°äº†ä¸€äº›é€šç”¨è§„å¾‹**")
        print("   è™½ç„¶åœ¨Level 3ä¸Šè¡¨ç°æœ€å¥½ï¼Œä½†åœ¨å…¶ä»–æ•°æ®ä¸Šä¹Ÿæœ‰åˆç†è¡¨ç°")
        
    elif l1_acc > l3_acc:
        print("ğŸ¤” **æ„å¤–ç»“æœ**")
        print("   æ¨¡å‹åœ¨ç®€å•æ•°æ®ä¸Šè¡¨ç°æ›´å¥½ï¼Œè¿™å¯èƒ½è¡¨æ˜è®­ç»ƒè¿‡ç¨‹æœ‰é—®é¢˜")
        
    else:
        print("ğŸ“Š **éœ€è¦æ›´å¤šåˆ†æ**")
        print("   ç»“æœä¸å¤Ÿæ˜ç¡®ï¼Œå»ºè®®å¢åŠ æ ·æœ¬æ•°é‡æˆ–æ£€æŸ¥å…¶ä»–å› ç´ ")
    
    # ç»™å‡ºå…·ä½“å»ºè®®
    print(f"\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
    if l3_acc > 0.8 and l1_acc < 0.1:
        print("1. ç«‹å³é‡æ–°è®¾è®¡Level 3æ•°æ®ç”Ÿæˆç­–ç•¥")
        print("2. å¢åŠ å™ªå£°çš„å¤šæ ·æ€§å’Œå¤æ‚åº¦")
        print("3. ç¡®ä¿ä¸åŒå¤æ‚åº¦æ•°æ®ä¹‹é—´çš„ä¸€è‡´æ€§")
        print("4. é‡æ–°ç”Ÿæˆæ•°æ®å¹¶é‡æ–°è®­ç»ƒ")
    else:
        print("1. ç»§ç»­è®­ç»ƒæ›´å¤šè½®æ¬¡")
        print("2. è°ƒæ•´å­¦ä¹ ç‡å’Œè®­ç»ƒç­–ç•¥")
        print("3. è€ƒè™‘è¯¾ç¨‹å­¦ä¹ æ–¹æ³•")


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ”¬ å¼€å§‹Level 3æ¨¡å‹çš„äº¤å‰è¯„ä¼°æµ‹è¯•...")
    
    # è¿è¡Œäº¤å‰è¯„ä¼°
    results = run_cross_evaluation()
    
    # åˆ†æç»“æœ
    analyze_cross_evaluation_results(results)
    
    print(f"\nğŸ‰ äº¤å‰è¯„ä¼°æµ‹è¯•å®Œæˆï¼")


if __name__ == "__main__":
    main()
