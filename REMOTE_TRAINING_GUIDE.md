# ğŸš€ è¿œç¨‹ç®—åŠ›è®­ç»ƒä½¿ç”¨æŒ‡å—

## ğŸ“‹ æ¦‚è¿°

æœ¬æŒ‡å—ä»‹ç»å¦‚ä½•ä½¿ç”¨è‡ªåç§»æ¨ç†è®­ç»ƒé¡¹ç›®çš„è¿œç¨‹ç®—åŠ›è®­ç»ƒç³»ç»Ÿï¼Œæ”¯æŒå¤šç§äº‘å¹³å°å’Œå®¹å™¨åŒ–éƒ¨ç½²ã€‚

## ğŸ¯ ç³»ç»Ÿæ¶æ„

```
æœ¬åœ°å¼€å‘ç¯å¢ƒ
    â†“ (æ•°æ®åŒæ­¥)
äº‘ç«¯å­˜å‚¨ (S3/OSS/GCS/Azure)
    â†“ (å®¹å™¨åŒ–éƒ¨ç½²)
Kubernetesé›†ç¾¤ (GPUèŠ‚ç‚¹)
    â†“ (è®­ç»ƒæ‰§è¡Œ)
è¿œç¨‹è®­ç»ƒç³»ç»Ÿ
    â†“ (ç»“æœåŒæ­¥)
äº‘ç«¯å­˜å‚¨ + ç›‘æ§ç³»ç»Ÿ
```

## ğŸ› ï¸ å¿«é€Ÿå¼€å§‹

### 1. ç¯å¢ƒå‡†å¤‡

#### æœ¬åœ°ç¯å¢ƒ
```bash
# å®‰è£…ä¾èµ–
pip install -r requirements.txt
pip install -r requirements_remote.txt

# å®‰è£…Docker
# å®‰è£…kubectl (Kuberneteså‘½ä»¤è¡Œå·¥å…·)
# å®‰è£…äº‘å¹³å°CLIå·¥å…·
```

#### äº‘å¹³å°é…ç½®
```bash
# é˜¿é‡Œäº‘
aliyun configure

# AWS
aws configure

# Google Cloud
gcloud auth login

# Azure
az login
```

### 2. é…ç½®è®¾ç½®

#### åˆ›å»ºé…ç½®æ–‡ä»¶
```bash
python remote_training_config.py
```

#### ç¯å¢ƒå˜é‡é…ç½®
```bash
# è®­ç»ƒå‚æ•°
export EPOCHS=100
export BATCH_SIZE=64
export LEARNING_RATE=0.001

# äº‘å­˜å‚¨é…ç½®
export CLOUD_PROVIDER=aliyun  # aws, gcp, azure, aliyun
export CLOUD_BUCKET=your-bucket-name
export CLOUD_ACCESS_KEY=your-access-key
export CLOUD_SECRET_KEY=your-secret-key

# è·¯å¾„é…ç½®
export REMOTE_DATA_PATH=/data/logic_training
export REMOTE_OUTPUT_PATH=/outputs/training_results
```

### 3. æ•°æ®å‡†å¤‡

#### åŒæ­¥è®­ç»ƒæ•°æ®åˆ°äº‘ç«¯
```bash
# ç”Ÿæˆå¹¶ä¸Šä¼ æ•°æ®
python sync_data_to_remote.py --action upload --force-regenerate

# ä»…ä¸Šä¼ ç°æœ‰æ•°æ®
python sync_data_to_remote.py --action upload
```

### 4. éƒ¨ç½²é€‰é¡¹

#### é€‰é¡¹A: æœ¬åœ°Dockeræµ‹è¯•
```bash
# æ„å»ºé•œåƒ
docker build -t logic-training:latest .

# è¿è¡Œå®¹å™¨
docker run -it --rm \
  -e EPOCHS=20 \
  -e BATCH_SIZE=16 \
  -e DEBUG_MODE=true \
  -v $(pwd)/data:/data/logic_training:ro \
  -v $(pwd)/outputs:/outputs \
  logic-training:latest
```

#### é€‰é¡¹B: Docker Composeæœ¬åœ°é›†ç¾¤
```bash
# åˆ›å»ºå¿…è¦ç›®å½•
mkdir -p volumes/{models,outputs,checkpoints} logs

# å¯åŠ¨æœåŠ¡
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f logic-training

# åœæ­¢æœåŠ¡
docker-compose down
```

#### é€‰é¡¹C: Kubernetesäº‘ç«¯éƒ¨ç½²
```bash
# éƒ¨ç½²åˆ°äº‘ç«¯
chmod +x deploy_to_cloud.sh
./deploy_to_cloud.sh --cloud-provider aliyun --version v1.0

# ç›‘æ§è®­ç»ƒçŠ¶æ€
kubectl get jobs -n logic-training
kubectl logs -f job/logic-training-job -n logic-training
```

## ğŸ“Š ç›‘æ§å’Œç®¡ç†

### è®­ç»ƒçŠ¶æ€ç›‘æ§
```bash
# æŸ¥çœ‹PodçŠ¶æ€
kubectl get pods -n logic-training

# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
kubectl logs -f deployment/logic-training -n logic-training

# æŸ¥çœ‹èµ„æºä½¿ç”¨
kubectl top pods -n logic-training
```

### æ£€æŸ¥ç‚¹ç®¡ç†
```bash
# åŒæ­¥æ£€æŸ¥ç‚¹åˆ°äº‘ç«¯
python sync_data_to_remote.py --action sync-checkpoints

# ä¸‹è½½æ£€æŸ¥ç‚¹
python sync_data_to_remote.py --action download
```

## ğŸ”§ é«˜çº§é…ç½®

### åˆ†å¸ƒå¼è®­ç»ƒ
```yaml
# k8s-training-job.yaml
env:
- name: USE_DISTRIBUTED
  value: "true"
- name: WORLD_SIZE
  value: "4"  # 4ä¸ªGPU
```

### è‡ªå®šä¹‰èµ„æºé…ç½®
```yaml
resources:
  requests:
    nvidia.com/gpu: "2"  # è¯·æ±‚2ä¸ªGPU
    memory: "16Gi"
    cpu: "8"
  limits:
    nvidia.com/gpu: "2"
    memory: "32Gi"
    cpu: "16"
```

### ç›‘æ§é›†æˆ
```bash
# å¯ç”¨Weights & Biases
export ENABLE_WANDB=true
export WANDB_PROJECT=logic-training
export WANDB_ENTITY=your-team

# å¯ç”¨Slacké€šçŸ¥
export SLACK_WEBHOOK=your-webhook-url
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### æ•°æ®åŠ è½½ä¼˜åŒ–
```python
# åœ¨é…ç½®ä¸­è®¾ç½®
DATA_WORKERS=8
PREFETCH_FACTOR=4
```

### GPUå†…å­˜ä¼˜åŒ–
```bash
export GPU_MEMORY_LIMIT=8Gi
export BATCH_SIZE=32  # æ ¹æ®GPUå†…å­˜è°ƒæ•´
```

### ç½‘ç»œä¼˜åŒ–
```bash
# ä½¿ç”¨æ›´å¿«çš„å­˜å‚¨ç±»
storageClassName: fast-ssd
```

## ğŸš¨ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. å®¹å™¨å¯åŠ¨å¤±è´¥
```bash
# æ£€æŸ¥é•œåƒ
docker images | grep logic-training

# æ£€æŸ¥æ—¥å¿—
docker logs container-name

# æ£€æŸ¥èµ„æº
kubectl describe pod pod-name -n logic-training
```

#### 2. æ•°æ®åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ•°æ®æ–‡ä»¶
ls -la /data/logic_training/

# æ£€æŸ¥æƒé™
kubectl exec -it pod-name -n logic-training -- ls -la /data/
```

#### 3. GPUä¸å¯ç”¨
```bash
# æ£€æŸ¥GPUèŠ‚ç‚¹
kubectl get nodes -l accelerator=nvidia-tesla-v100

# æ£€æŸ¥GPUèµ„æº
kubectl describe node node-name
```

#### 4. ç½‘ç»œè¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥ç½‘ç»œç­–ç•¥
kubectl get networkpolicy -n logic-training

# æµ‹è¯•è¿æ¥
kubectl exec -it pod-name -n logic-training -- ping google.com
```

### è°ƒè¯•æ¨¡å¼
```bash
# å¯ç”¨è°ƒè¯•æ¨¡å¼
export DEBUG_MODE=true

# å¹²è¿è¡Œæµ‹è¯•
export DRY_RUN=true

# è¯¦ç»†æ—¥å¿—
export LOG_LEVEL=DEBUG
```

## ğŸ“‹ æœ€ä½³å®è·µ

### 1. èµ„æºç®¡ç†
- æ ¹æ®æ•°æ®å¤§å°å’Œæ¨¡å‹å¤æ‚åº¦åˆç†é…ç½®èµ„æº
- ä½¿ç”¨èµ„æºé…é¢é˜²æ­¢è¿‡åº¦ä½¿ç”¨
- å®šæœŸæ¸…ç†ä¸éœ€è¦çš„æ£€æŸ¥ç‚¹

### 2. å®‰å…¨é…ç½®
- ä½¿ç”¨Kubernetes Secretsç®¡ç†æ•æ„Ÿä¿¡æ¯
- é…ç½®ç½‘ç»œç­–ç•¥é™åˆ¶è®¿é—®
- å®šæœŸæ›´æ–°å®¹å™¨é•œåƒ

### 3. æˆæœ¬ä¼˜åŒ–
- ä½¿ç”¨æŠ¢å å¼å®ä¾‹é™ä½æˆæœ¬
- é…ç½®è‡ªåŠ¨ç¼©æ”¾
- ç›‘æ§èµ„æºä½¿ç”¨æƒ…å†µ

### 4. æ•°æ®ç®¡ç†
- å®šæœŸå¤‡ä»½é‡è¦æ•°æ®
- ä½¿ç”¨ç‰ˆæœ¬æ§åˆ¶ç®¡ç†æ•°æ®é›†
- ä¼˜åŒ–æ•°æ®ä¼ è¾“æ•ˆç‡

## ğŸ¯ ç¤ºä¾‹å·¥ä½œæµ

### å®Œæ•´è®­ç»ƒæµç¨‹
```bash
# 1. å‡†å¤‡æ•°æ®
python sync_data_to_remote.py --action upload --force-regenerate

# 2. éƒ¨ç½²è®­ç»ƒä»»åŠ¡
./deploy_to_cloud.sh --cloud-provider aliyun --version v1.0

# 3. ç›‘æ§è®­ç»ƒ
kubectl logs -f job/logic-training-job -n logic-training

# 4. ä¸‹è½½ç»“æœ
python sync_data_to_remote.py --action sync-checkpoints

# 5. æ¸…ç†èµ„æº
kubectl delete job logic-training-job -n logic-training
```

## ğŸ“ æ”¯æŒå’Œåé¦ˆ

å¦‚æœé‡åˆ°é—®é¢˜æˆ–æœ‰æ”¹è¿›å»ºè®®ï¼Œè¯·ï¼š

1. æŸ¥çœ‹æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
2. æ£€æŸ¥é…ç½®æ˜¯å¦æ­£ç¡®
3. å‚è€ƒæ•…éšœæ’é™¤éƒ¨åˆ†
4. åœ¨GitHubä»“åº“æäº¤Issue

---

**ğŸ‰ ç°åœ¨æ‚¨å¯ä»¥åœ¨äº‘ç«¯è¿›è¡Œå¤§è§„æ¨¡çš„è‡ªåç§»æ¨ç†è®­ç»ƒäº†ï¼**
