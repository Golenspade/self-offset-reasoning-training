#!/usr/bin/env python3
"""
åˆ†æè´´å§é¡µé¢ç»“æ„ï¼Œæ‰¾åˆ°æ­£ç¡®çš„é€‰æ‹©å™¨
"""

import asyncio
import json
from playwright.async_api import async_playwright


async def analyze_tieba_page():
    """åˆ†æè´´å§é¡µé¢ç»“æ„"""
    async with async_playwright() as p:
        browser = await p.chromium.launch(headless=False)

        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36",
        )

        # åŠ è½½ Cookie
        with open("baidu_cookies.json", "r") as f:
            cookies = json.load(f)
            await context.add_cookies(cookies)
            print(f"âœ… å·²åŠ è½½ {len(cookies)} ä¸ª Cookie")

        page = await context.new_page()

        url = "https://tieba.baidu.com/f?ie=utf-8&kw=é‚¦å¤šåˆ©æ€€å­•"
        print(f"ğŸŒ è®¿é—®: {url}")

        await page.goto(url, timeout=60000)
        await asyncio.sleep(3)

        title = await page.title()
        print(f"ğŸ“„ é¡µé¢æ ‡é¢˜: {title}")

        if "å®‰å…¨éªŒè¯" in title:
            print("âŒ ä»ç„¶éœ€è¦éªŒè¯ç ï¼ŒCookie å¯èƒ½å·²è¿‡æœŸ")
            return

        print("\nğŸ” åˆ†æé¡µé¢ç»“æ„...")

        # å°è¯•å„ç§å¯èƒ½çš„é€‰æ‹©å™¨
        selectors = {
            "å¸–å­åˆ—è¡¨é¡¹": [
                'li[class*="thread"]',
                "li.j_thread_list",
                ".threadlist_lz",
                ".threadlist_bright",
                "ul#thread_list li",
                "li[data-field]",
            ],
            "å¸–å­æ ‡é¢˜": [
                "a.j_th_tit",
                ".threadlist_title a",
                'a[href*="/p/"]',
                ".ti_title a",
                "div.threadlist_title a",
            ],
            "ä½œè€…": [
                ".tb_icon_author",
                ".threadlist_author",
                "span.tb_icon_author",
                'span[class*="author"]',
            ],
            "å›å¤æ•°": [
                ".threadlist_rep_num",
                ".tb_icon_reply_num",
                "span.threadlist_rep_num",
            ],
        }

        results = {}

        for category, selector_list in selectors.items():
            print(f"\nğŸ“¦ {category}:")
            for selector in selector_list:
                try:
                    elements = await page.query_selector_all(selector)
                    count = len(elements)

                    if count > 0:
                        print(f"  âœ… {selector}: {count} ä¸ª")

                        # è·å–å‰3ä¸ªå…ƒç´ çš„æ–‡æœ¬
                        samples = []
                        for elem in elements[:3]:
                            try:
                                text = await elem.inner_text()
                                text = text.strip()[:80]
                                if text:
                                    samples.append(text)
                            except:
                                pass

                        if samples:
                            results[category] = {
                                "selector": selector,
                                "count": count,
                                "samples": samples,
                            }
                            for i, sample in enumerate(samples):
                                print(f"      [{i}] {sample}")
                            break  # æ‰¾åˆ°ä¸€ä¸ªå°±å¤Ÿäº†
                    else:
                        print(f"  âŒ {selector}: 0 ä¸ª")
                except Exception as e:
                    print(f"  âš ï¸  {selector}: é”™è¯¯ - {e}")

        # ä¿å­˜ç»“æœ
        with open("page_analysis.json", "w", encoding="utf-8") as f:
            json.dump(results, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ åˆ†æç»“æœå·²ä¿å­˜åˆ° page_analysis.json")

        # å°è¯•æå–ä¸€ä¸ªå®Œæ•´çš„å¸–å­æ•°æ®
        print("\nğŸ¯ å°è¯•æå–ç¬¬ä¸€ä¸ªå¸–å­çš„å®Œæ•´æ•°æ®...")

        if "å¸–å­åˆ—è¡¨é¡¹" in results:
            thread_selector = results["å¸–å­åˆ—è¡¨é¡¹"]["selector"]
            threads = await page.query_selector_all(thread_selector)

            if threads:
                first_thread = threads[0]

                # å°è¯•æå–å„ç§ä¿¡æ¯
                data = {}

                # æ ‡é¢˜
                if "å¸–å­æ ‡é¢˜" in results:
                    title_elem = await first_thread.query_selector(
                        results["å¸–å­æ ‡é¢˜"]["selector"]
                    )
                    if title_elem:
                        data["title"] = await title_elem.inner_text()
                        data["link"] = await title_elem.get_attribute("href")

                # ä½œè€…
                if "ä½œè€…" in results:
                    author_elem = await first_thread.query_selector(
                        results["ä½œè€…"]["selector"]
                    )
                    if author_elem:
                        data["author"] = await author_elem.inner_text()

                # å›å¤æ•°
                if "å›å¤æ•°" in results:
                    reply_elem = await first_thread.query_selector(
                        results["å›å¤æ•°"]["selector"]
                    )
                    if reply_elem:
                        data["replies"] = await reply_elem.inner_text()

                print("\nğŸ“ æå–çš„æ•°æ®:")
                for key, value in data.items():
                    print(f"  {key}: {value}")

        print("\nâ¸ï¸  æµè§ˆå™¨å°†ä¿æŒæ‰“å¼€ 30 ç§’ï¼Œå¯ä»¥æ‰‹åŠ¨æ£€æŸ¥...")
        await asyncio.sleep(30)

        await browser.close()


if __name__ == "__main__":
    asyncio.run(analyze_tieba_page())
