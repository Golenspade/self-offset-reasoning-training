#!/usr/bin/env python3
"""
äº¤äº’å¼è´´å§çˆ¬è™« - æ‰‹åŠ¨å®ŒæˆéªŒè¯ï¼Œè‡ªåŠ¨çˆ¬å–
"""

import asyncio
import json
from datetime import datetime
from playwright.async_api import async_playwright


async def wait_for_user_verification(page):
    """ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨å®ŒæˆéªŒè¯ç """
    print("\n" + "=" * 60)
    print("âš ï¸  è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®Œæˆä»¥ä¸‹æ“ä½œï¼š")
    print("   1. å®Œæˆæ»‘å—éªŒè¯ç ï¼ˆå¦‚æœæœ‰ï¼‰")
    print("   2. ç™»å½•ç™¾åº¦è´¦å·ï¼ˆå¯é€‰ï¼Œä½†å»ºè®®ç™»å½•ä»¥å‡å°‘éªŒè¯ç ï¼‰")
    print("   3. ç¡®ä¿èƒ½çœ‹åˆ°è´´å§å¸–å­åˆ—è¡¨")
    print("   4. å®Œæˆåï¼Œåœ¨ç»ˆç«¯æŒ‰ Enter ç»§ç»­...")
    print("=" * 60 + "\n")

    # ç­‰å¾…ç”¨æˆ·æŒ‰ Enter
    await asyncio.get_event_loop().run_in_executor(None, input, "æŒ‰ Enter ç»§ç»­ >>> ")

    # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
    title = await page.title()
    if "å®‰å…¨éªŒè¯" in title or "ç™»å½•" in title:
        print("âš ï¸  ä¼¼ä¹è¿˜æ²¡æœ‰å®ŒæˆéªŒè¯ï¼Œä½†ç»§ç»­å°è¯•...")
    else:
        print(f"âœ… é¡µé¢æ ‡é¢˜: {title}")

    return True


async def extract_threads_from_page(page):
    """ä»å½“å‰é¡µé¢æå–å¸–å­"""
    print("\nğŸ” å¼€å§‹æå–å¸–å­...")

    # ç­‰å¾…é¡µé¢åŠ è½½
    await asyncio.sleep(2)

    # å°è¯•å¤šç§é€‰æ‹©å™¨
    thread_selectors = [
        'li[class*="thread"]',
        "li.j_thread_list",
        ".threadlist_lz",
    ]

    threads = []
    for selector in thread_selectors:
        threads = await page.query_selector_all(selector)
        if threads:
            print(f"âœ… ä½¿ç”¨é€‰æ‹©å™¨ '{selector}' æ‰¾åˆ° {len(threads)} ä¸ªå¸–å­")
            break

    if not threads:
        print("âŒ æœªæ‰¾åˆ°å¸–å­åˆ—è¡¨ï¼")
        return []

    judgments = []

    for i, thread in enumerate(threads[:20]):  # æ¯é¡µæœ€å¤šå–20ä¸ª
        try:
            # æå–æ ‡é¢˜
            title_elem = await thread.query_selector("a.j_th_tit")
            if not title_elem:
                title_elem = await thread.query_selector('a[href*="/p/"]')

            if not title_elem:
                continue

            title = await title_elem.inner_text()
            title = title.strip()

            if not title:
                continue

            # è¿‡æ»¤ï¼šåªè¦åŒ…å«åˆ¤æ–­æ€§å…³é”®è¯çš„å¸–å­
            judgment_keywords = [
                "å—",
                "ï¼Ÿ",
                "èƒ½",
                "ä¼š",
                "æ˜¯",
                "ä¸",
                "æ²¡",
                "åˆ«",
                "å¤ª",
                "æ€ä¹ˆ",
                "ä¸ºä»€ä¹ˆ",
                "å¦‚ä½•",
                "æœ‰",
                "è¦",
            ]
            if not any(kw in title for kw in judgment_keywords):
                continue

            # æå–ä½œè€…
            author_elem = await thread.query_selector(".tb_icon_author")
            if not author_elem:
                author_elem = await thread.query_selector('span[class*="author"]')
            author = await author_elem.inner_text() if author_elem else "åŒ¿å"

            # æå–å›å¤æ•°
            reply_elem = await thread.query_selector(".threadlist_rep_num")
            if not reply_elem:
                reply_elem = await thread.query_selector('span[class*="reply"]')
            replies = await reply_elem.inner_text() if reply_elem else "0"

            judgment = {
                "title": title,
                "content": f"æ¥è‡ªè´´å§çš„è®¨è®ºï¼š{title}",
                "author": author.strip(),
                "upvotes": int(replies.strip()) if replies.strip().isdigit() else 0,
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "source": "è´´å§",
            }

            judgments.append(judgment)
            print(f"  [{i+1}] {title[:50]}... (å›å¤: {replies})")

        except Exception as e:
            print(f"  âš ï¸  æå–ç¬¬ {i+1} ä¸ªå¸–å­å¤±è´¥: {e}")
            continue

    print(f"\nâœ… æˆåŠŸæå– {len(judgments)} æ¡åˆ¤ä¾‹")
    return judgments


async def crawl_tieba_interactive(tieba_name: str, max_pages: int = 3):
    """äº¤äº’å¼çˆ¬å–è´´å§"""
    print(f"\nğŸ¯ å¼€å§‹çˆ¬å–è´´å§: {tieba_name}")
    print(f"ğŸ“„ è®¡åˆ’çˆ¬å– {max_pages} é¡µ\n")

    async with async_playwright() as p:
        # å¯åŠ¨æµè§ˆå™¨ï¼ˆé headlessï¼‰
        browser = await p.chromium.launch(
            headless=False,
            slow_mo=50,  # å‡æ…¢æ“ä½œï¼Œæ›´åƒäººç±»
        )

        context = await browser.new_context(
            viewport={"width": 1920, "height": 1080},
            user_agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
            locale="zh-CN",
        )

        page = await context.new_page()

        all_judgments = []

        for page_num in range(max_pages):
            url = (
                f"https://tieba.baidu.com/f?ie=utf-8&kw={tieba_name}&pn={page_num * 50}"
            )
            print(f"\nğŸ“„ ç¬¬ {page_num + 1}/{max_pages} é¡µ")
            print(f"ğŸŒ è®¿é—®: {url}")

            # è®¿é—®é¡µé¢
            await page.goto(url, timeout=60000)
            await asyncio.sleep(2)

            # ç¬¬ä¸€æ¬¡è®¿é—®æ—¶ï¼Œç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨éªŒè¯
            if page_num == 0:
                await wait_for_user_verification(page)

            # æå–å¸–å­
            judgments = await extract_threads_from_page(page)
            all_judgments.extend(judgments)

            # éšæœºå»¶æ—¶
            if page_num < max_pages - 1:
                delay = 3 + page_num  # é€æ¸å¢åŠ å»¶æ—¶
                print(f"\nâ³ ç­‰å¾… {delay} ç§’åç»§ç»­...")
                await asyncio.sleep(delay)

        # ä¿å­˜ç»“æœ
        output_file = "../data/raw/raw_judgments.json"
        print(f"\nğŸ’¾ ä¿å­˜æ•°æ®åˆ°: {output_file}")

        import os

        os.makedirs(os.path.dirname(output_file), exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(all_judgments, f, ensure_ascii=False, indent=2)

        print(f"âœ… å…±çˆ¬å– {len(all_judgments)} æ¡åˆ¤ä¾‹")
        print(f"ğŸ“Š æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")

        # ä¿æŒæµè§ˆå™¨æ‰“å¼€ä¸€ä¼šå„¿
        print("\nâ¸ï¸  æµè§ˆå™¨å°†åœ¨ 10 ç§’åå…³é—­...")
        await asyncio.sleep(10)

        await browser.close()

        return all_judgments


async def main():
    """ä¸»å‡½æ•°"""
    # çˆ¬å–å¤šä¸ªè´´å§
    tieba_list = [
        "é‚¦å¤šåˆ©æ€€å­•",
        "å¼±æ™º",
        "æŠ—å‹",
    ]

    all_data = []

    for tieba in tieba_list:
        try:
            data = await crawl_tieba_interactive(tieba, max_pages=2)
            all_data.extend(data)
        except Exception as e:
            print(f"âŒ çˆ¬å– {tieba} å¤±è´¥: {e}")
            continue

    print(f"\nğŸ‰ å…¨éƒ¨å®Œæˆï¼å…±çˆ¬å– {len(all_data)} æ¡æ•°æ®")


if __name__ == "__main__":
    asyncio.run(main())
