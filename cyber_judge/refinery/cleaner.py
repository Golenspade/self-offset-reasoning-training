#!/usr/bin/env python3
"""
èµ›åšè£åˆ¤é•¿ - æ•°æ®æ¸…æ´—æ¨¡å— (The Refinery)
åŠŸèƒ½: æ¸…æ´—çˆ¬è™«æŠ“å–çš„åŸå§‹æ•°æ®ï¼Œå»é™¤å™ªå£°ï¼Œæ ¼å¼åŒ–è¾“å‡º
"""

import json
import re
from pathlib import Path
from typing import List, Dict, Optional
import pandas as pd
from dataclasses import dataclass, asdict


@dataclass
class CleanedJudgment:
    """æ¸…æ´—åçš„åˆ¤ä¾‹æ•°æ®"""
    instruction: str  # æ¡ˆæƒ…æè¿°
    output: str       # åˆ¤å†³ç»“æœ
    source: str       # æ¥æº
    quality_score: float  # è´¨é‡åˆ†æ•° 0-1
    

class DataCleaner:
    """æ•°æ®æ¸…æ´—å™¨"""
    
    def __init__(self):
        # HTMLæ ‡ç­¾æ­£åˆ™
        self.html_pattern = re.compile(r'<[^>]+>')
        # è¡¨æƒ…åŒ…ä»£ç æ­£åˆ™
        self.emoji_pattern = re.compile(r'\[.*?\]')
        # åºŸè¯è¿‡æ»¤ï¼ˆå¤ªçŸ­çš„å›å¤ï¼‰
        self.min_length = 5
        # æ— æ„ä¹‰å›å¤
        self.useless_replies = {'æ’çœ¼', 'é¡¶', 'æ²™å‘', 'å‰æ’', 'ç•™å', 'è·¯è¿‡'}
        
    def clean_text(self, text: str) -> str:
        """æ¸…æ´—å•æ¡æ–‡æœ¬"""
        if not text:
            return ""
        
        # å»é™¤HTMLæ ‡ç­¾
        text = self.html_pattern.sub('', text)
        # å»é™¤è¡¨æƒ…åŒ…ä»£ç 
        text = self.emoji_pattern.sub('', text)
        # å»é™¤å¤šä½™ç©ºç™½
        text = ' '.join(text.split())
        # å»é™¤é¦–å°¾ç©ºæ ¼
        text = text.strip()
        
        return text
    
    def is_valid_verdict(self, verdict: str) -> bool:
        """åˆ¤æ–­æ˜¯å¦æ˜¯æœ‰æ•ˆçš„åˆ¤å†³"""
        if not verdict or len(verdict) < self.min_length:
            return False
        
        # è¿‡æ»¤æ— æ„ä¹‰å›å¤
        if verdict in self.useless_replies:
            return False
        
        # å¿…é¡»åŒ…å«è‡³å°‘ä¸€ä¸ªå…³é”®è¯
        keywords = ['é‰´å®šä¸º', 'çº¯çº¯çš„', 'æœ‰ä¸€è¯´ä¸€', 'å±äºæ˜¯', 'é©³å›', 'å»ºè®®', 'èµ›åš']
        if not any(kw in verdict for kw in keywords):
            return False
        
        return True
    
    def calculate_quality_score(self, judgment: Dict) -> float:
        """è®¡ç®—åˆ¤ä¾‹è´¨é‡åˆ†æ•°"""
        score = 0.0
        
        # ç‚¹èµæ•°æƒé‡
        upvotes = judgment.get('upvotes', 0)
        score += min(upvotes / 100, 0.4)  # æœ€å¤š0.4åˆ†
        
        # å…³é”®è¯æ•°é‡æƒé‡
        keywords = judgment.get('keywords', [])
        score += min(len(keywords) * 0.1, 0.3)  # æœ€å¤š0.3åˆ†
        
        # æ–‡æœ¬é•¿åº¦æƒé‡ï¼ˆé€‚ä¸­æœ€å¥½ï¼‰
        verdict_len = len(judgment.get('verdict', ''))
        if 10 <= verdict_len <= 100:
            score += 0.3
        elif verdict_len > 100:
            score += 0.15
        
        return min(score, 1.0)
    
    def clean_judgment(self, raw_judgment: Dict) -> Optional[CleanedJudgment]:
        """æ¸…æ´—å•æ¡åˆ¤ä¾‹"""
        case = self.clean_text(raw_judgment.get('case', ''))
        verdict = self.clean_text(raw_judgment.get('verdict', ''))
        
        # éªŒè¯æœ‰æ•ˆæ€§
        if not case or not self.is_valid_verdict(verdict):
            return None
        
        quality_score = self.calculate_quality_score(raw_judgment)
        
        # è´¨é‡åˆ†æ•°å¤ªä½åˆ™ä¸¢å¼ƒ
        if quality_score < 0.3:
            return None
        
        return CleanedJudgment(
            instruction=case,
            output=verdict,
            source=raw_judgment.get('source', ''),
            quality_score=quality_score
        )
    
    def clean_dataset(self, input_file: Path, output_file: Path, 
                     min_quality: float = 0.5) -> List[CleanedJudgment]:
        """æ¸…æ´—æ•´ä¸ªæ•°æ®é›†"""
        print(f"ğŸ§¹ å¼€å§‹æ¸…æ´—æ•°æ®: {input_file}")
        
        # è¯»å–åŸå§‹æ•°æ®
        with open(input_file, 'r', encoding='utf-8') as f:
            raw_data = json.load(f)
        
        print(f"ğŸ“Š åŸå§‹æ•°æ®é‡: {len(raw_data)}")
        
        # æ¸…æ´—æ•°æ®
        cleaned_data = []
        for raw_judgment in raw_data:
            cleaned = self.clean_judgment(raw_judgment)
            if cleaned and cleaned.quality_score >= min_quality:
                cleaned_data.append(cleaned)
        
        print(f"âœ… æ¸…æ´—åæ•°æ®é‡: {len(cleaned_data)}")
        print(f"ğŸ“‰ è¿‡æ»¤ç‡: {(1 - len(cleaned_data)/len(raw_data))*100:.1f}%")
        
        # ä¿å­˜æ¸…æ´—åçš„æ•°æ®
        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump([asdict(j) for j in cleaned_data], f, 
                     ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ å·²ä¿å­˜è‡³: {output_file}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self.generate_report(cleaned_data, output_file.parent / 'cleaning_report.txt')
        
        return cleaned_data
    
    def generate_report(self, data: List[CleanedJudgment], report_file: Path):
        """ç”Ÿæˆæ¸…æ´—æŠ¥å‘Š"""
        df = pd.DataFrame([asdict(j) for j in data])
        
        report = f"""
=== æ•°æ®æ¸…æ´—æŠ¥å‘Š ===

æ€»æ•°æ®é‡: {len(data)}

è´¨é‡åˆ†æ•°åˆ†å¸ƒ:
{df['quality_score'].describe()}

å¹³å‡æŒ‡ä»¤é•¿åº¦: {df['instruction'].str.len().mean():.1f}
å¹³å‡è¾“å‡ºé•¿åº¦: {df['output'].str.len().mean():.1f}

è´¨é‡åˆ†æ•° >= 0.8 çš„æ•°æ®: {len(df[df['quality_score'] >= 0.8])}
è´¨é‡åˆ†æ•° >= 0.6 çš„æ•°æ®: {len(df[df['quality_score'] >= 0.6])}
è´¨é‡åˆ†æ•° >= 0.5 çš„æ•°æ®: {len(df[df['quality_score'] >= 0.5])}
"""
        
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write(report)
        
        print(f"ğŸ“‹ æŠ¥å‘Šå·²ç”Ÿæˆ: {report_file}")


def main():
    """ä¸»å‡½æ•°"""
    cleaner = DataCleaner()
    
    input_file = Path(__file__).parent.parent / 'data' / 'raw' / 'raw_judgments.json'
    output_file = Path(__file__).parent.parent / 'data' / 'processed' / 'cleaned_judgments.json'
    
    cleaner.clean_dataset(input_file, output_file, min_quality=0.5)


if __name__ == '__main__':
    main()

