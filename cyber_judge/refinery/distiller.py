#!/usr/bin/env python3
"""
èµ›åšè£åˆ¤é•¿ - LLM æ•°æ®è’¸é¦æ¨¡å—
åŠŸèƒ½: ä½¿ç”¨ LLM å¯¹æ¸…æ´—åçš„æ•°æ®è¿›è¡Œè¿›ä¸€æ­¥æç‚¼å’Œæ ¼å¼åŒ–
"""

import json
import asyncio
from pathlib import Path
from typing import List, Dict
from dataclasses import dataclass, asdict
import os


@dataclass
class DistilledExample:
    """è’¸é¦åçš„ç¤ºä¾‹"""

    instruction: str
    output: str
    reasoning: str  # LLM æå–çš„æ¨ç†è¿‡ç¨‹
    style_tags: List[str]  # é£æ ¼æ ‡ç­¾


class LLMDistiller:
    """LLM è’¸é¦å™¨"""

    def __init__(self, api_key: str = None, model: str = "llama-3.3-70b"):
        """
        åˆå§‹åŒ–è’¸é¦å™¨

        Args:
            api_key: Cerebras API Key (å¦‚æœä¸ºç©ºåˆ™ä»ç¯å¢ƒå˜é‡è¯»å–)
            model: ä½¿ç”¨çš„æ¨¡å‹åç§°
        """
        self.api_key = api_key or os.getenv("CEREBRAS_API_KEY")
        self.model = model
        self.base_url = "https://api.cerebras.ai/v1"

        if not self.api_key:
            print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® CEREBRAS_API_KEYï¼Œè’¸é¦åŠŸèƒ½å°†ä¸å¯ç”¨")

    def create_distill_prompt(self, case: str, verdict: str) -> str:
        """åˆ›å»ºè’¸é¦æç¤ºè¯"""
        return f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°æ®æ ‡æ³¨ä¸“å®¶ã€‚è¯·åˆ†æä»¥ä¸‹å¯¹è¯ï¼Œæå–å…¶ä¸­çš„ç²¾åéƒ¨åˆ†ã€‚

åŸå§‹æ¡ˆæƒ…: {case}
åŸå§‹åˆ¤å†³: {verdict}

è¯·å®Œæˆä»¥ä¸‹ä»»åŠ¡:
1. å»é™¤è„è¯å’Œä¸æ–‡æ˜ç”¨è¯­ï¼Œä½†ä¿ç•™å¹½é»˜æ„Ÿå’Œè®½åˆºæ„å‘³
2. å°†åˆ¤å†³æ”¹å†™æˆ"æ³•å®˜åˆ¤è¯"çš„æ ¼å¼ï¼Œä½¿å…¶æ›´åŠ æ­£å¼ä½†ä¸å¤±è¶£å‘³
3. æå–åˆ¤å†³çš„æ¨ç†é€»è¾‘
4. æ ‡æ³¨åˆ¤å†³çš„é£æ ¼ç‰¹å¾ï¼ˆå¦‚ï¼šè®½åˆºã€ç›´æ¥ã€é˜´é˜³æ€ªæ°”ç­‰ï¼‰

è¯·ä»¥ JSON æ ¼å¼è¿”å›:
{{
  "instruction": "æ”¹å†™åçš„æ¡ˆæƒ…",
  "output": "æ”¹å†™åçš„åˆ¤å†³",
  "reasoning": "æ¨ç†è¿‡ç¨‹",
  "style_tags": ["é£æ ¼æ ‡ç­¾1", "é£æ ¼æ ‡ç­¾2"]
}}
"""

    async def distill_single(self, case: str, verdict: str) -> DistilledExample:
        """è’¸é¦å•æ¡æ•°æ®"""
        # TODO: å®ç°å®é™…çš„ API è°ƒç”¨
        # è¿™é‡Œæ˜¯ç¤ºä¾‹å®ç°

        # å¦‚æœæ²¡æœ‰ API Keyï¼Œè¿”å›ç®€å•å¤„ç†çš„ç»“æœ
        if not self.api_key:
            return DistilledExample(
                instruction=case,
                output=verdict,
                reasoning="æœªè¿›è¡Œ LLM è’¸é¦",
                style_tags=["åŸå§‹"],
            )

        # å®é™…å®ç°åº”è¯¥è°ƒç”¨ Cerebras API
        # response = await self.call_cerebras_api(prompt)
        # return parse_response(response)

        return DistilledExample(
            instruction=case,
            output=verdict,
            reasoning="ç¤ºä¾‹æ¨ç†è¿‡ç¨‹",
            style_tags=["è®½åˆº", "ç›´æ¥"],
        )

    async def distill_batch(
        self, data: List[Dict], max_concurrent: int = 5
    ) -> List[DistilledExample]:
        """æ‰¹é‡è’¸é¦æ•°æ®"""
        print(f"ğŸ§ª å¼€å§‹è’¸é¦æ•°æ®ï¼Œå…± {len(data)} æ¡")

        # åˆ›å»ºä»»åŠ¡é˜Ÿåˆ—
        semaphore = asyncio.Semaphore(max_concurrent)

        async def distill_with_limit(item):
            async with semaphore:
                return await self.distill_single(item["instruction"], item["output"])

        # å¹¶å‘æ‰§è¡Œ
        tasks = [distill_with_limit(item) for item in data]
        results = await asyncio.gather(*tasks)

        print(f"âœ… è’¸é¦å®Œæˆ")
        return results

    def save_for_production(self, examples: List[DistilledExample], output_file: Path):
        """ä¿å­˜ä¸ºç”Ÿäº§ç¯å¢ƒçš„ Few-Shot ç¤ºä¾‹"""
        # é€‰æ‹©é«˜è´¨é‡ç¤ºä¾‹ï¼ˆè¿™é‡Œç®€å•é€‰æ‹©å‰10æ¡ï¼‰
        top_examples = examples[:10]

        # æ ¼å¼åŒ–ä¸º Few-Shot æ ¼å¼
        few_shot_text = "# èµ›åšè£åˆ¤é•¿ - åˆ¤ä¾‹å‚è€ƒ\n\n"
        for i, ex in enumerate(top_examples, 1):
            few_shot_text += f"## åˆ¤ä¾‹ {i}\n"
            few_shot_text += f"ç”¨æˆ·: {ex.instruction}\n"
            few_shot_text += f"è£åˆ¤: {ex.output}\n\n"

        output_file.parent.mkdir(parents=True, exist_ok=True)
        with open(output_file, "w", encoding="utf-8") as f:
            f.write(few_shot_text)

        print(f"ğŸ’¾ Few-Shot ç¤ºä¾‹å·²ä¿å­˜: {output_file}")

    def save_for_training(self, examples: List[DistilledExample], output_file: Path):
        """ä¿å­˜ä¸ºè®­ç»ƒæ ¼å¼ (JSONL)"""
        output_file.parent.mkdir(parents=True, exist_ok=True)

        with open(output_file, "w", encoding="utf-8") as f:
            for ex in examples:
                # è½¬æ¢ä¸ºè®­ç»ƒæ ¼å¼
                train_item = {
                    "messages": [
                        {"role": "user", "content": ex.instruction},
                        {"role": "assistant", "content": ex.output},
                    ],
                    "metadata": {
                        "reasoning": ex.reasoning,
                        "style_tags": ex.style_tags,
                    },
                }
                f.write(json.dumps(train_item, ensure_ascii=False) + "\n")

        print(f"ğŸ’¾ è®­ç»ƒæ•°æ®å·²ä¿å­˜: {output_file}")


async def main():
    """ä¸»å‡½æ•°"""
    distiller = LLMDistiller()

    # è¯»å–æ¸…æ´—åçš„æ•°æ®
    input_file = (
        Path(__file__).parent.parent / "data" / "processed" / "cleaned_judgments.json"
    )

    if not input_file.exists():
        print(f"âŒ æ‰¾ä¸åˆ°è¾“å…¥æ–‡ä»¶: {input_file}")
        print("è¯·å…ˆè¿è¡Œ cleaner.py æ¸…æ´—æ•°æ®")
        return

    with open(input_file, "r", encoding="utf-8") as f:
        data = json.load(f)

    # è’¸é¦æ•°æ®
    distilled = await distiller.distill_batch(data)

    # ä¿å­˜ä¸ºä¸åŒæ ¼å¼
    base_path = Path(__file__).parent.parent / "data" / "examples"
    distiller.save_for_production(distilled, base_path / "production_examples.txt")
    distiller.save_for_training(distilled, base_path / "train.jsonl")


if __name__ == "__main__":
    asyncio.run(main())
