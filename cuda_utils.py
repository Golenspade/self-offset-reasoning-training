"""
æ–‡ä»¶å: cuda_utils.py
CUDAå·¥å…·æ¨¡å—
å¤„ç†GPUè®¾å¤‡æ£€æµ‹ã€å†…å­˜ç®¡ç†ã€æ€§èƒ½ä¼˜åŒ–ç­‰
"""
import os
import logging
import warnings
from typing import Dict, List, Optional, Tuple
from contextlib import contextmanager

# å°è¯•å¯¼å…¥CUDAç›¸å…³åº“
try:
    import torch
    import torch.cuda
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    warnings.warn("PyTorchæœªå®‰è£…ï¼ŒCUDAåŠŸèƒ½ä¸å¯ç”¨")

try:
    import nvidia_ml_py3 as nvml
    NVML_AVAILABLE = True
except ImportError:
    NVML_AVAILABLE = False
    warnings.warn("nvidia-ml-py3æœªå®‰è£…ï¼ŒGPUç›‘æ§åŠŸèƒ½å—é™")

try:
    import GPUtil
    GPUTIL_AVAILABLE = True
except ImportError:
    GPUTIL_AVAILABLE = False

logger = logging.getLogger(__name__)


class CUDAManager:
    """CUDAè®¾å¤‡å’Œå†…å­˜ç®¡ç†å™¨"""
    
    def __init__(self, memory_fraction: float = 0.8, auto_optimize: bool = True):
        """
        åˆå§‹åŒ–CUDAç®¡ç†å™¨
        
        Args:
            memory_fraction: GPUå†…å­˜ä½¿ç”¨æ¯”ä¾‹ (0.0-1.0)
            auto_optimize: æ˜¯å¦è‡ªåŠ¨ä¼˜åŒ–GPUè®¾ç½®
        """
        self.memory_fraction = memory_fraction
        self.auto_optimize = auto_optimize
        self.device = None
        self.device_properties = {}
        
        # åˆå§‹åŒ–NVML
        if NVML_AVAILABLE:
            try:
                nvml.nvmlInit()
                self.nvml_initialized = True
            except Exception as e:
                logger.warning(f"NVMLåˆå§‹åŒ–å¤±è´¥: {e}")
                self.nvml_initialized = False
        else:
            self.nvml_initialized = False
        
        # è·å–æœ€ä½³è®¾å¤‡
        self.device = self.get_best_device()
        
        # è‡ªåŠ¨ä¼˜åŒ–
        if self.auto_optimize and self.device.type == 'cuda':
            self.optimize_cuda_settings()
    
    def get_best_device(self):
        """è·å–æœ€ä½³è®¡ç®—è®¾å¤‡"""
        if not TORCH_AVAILABLE:
            logger.warning("âš ï¸ PyTorchæœªå®‰è£…ï¼Œä½¿ç”¨CPU")
            return 'cpu'
        
        if not torch.cuda.is_available():
            logger.warning("âš ï¸ CUDAä¸å¯ç”¨ï¼Œä½¿ç”¨CPU")
            return 'cpu'
        
        device_count = torch.cuda.device_count()
        logger.info(f"ğŸš€ å‘ç° {device_count} ä¸ªCUDAè®¾å¤‡")
        
        if device_count == 0:
            logger.warning("âš ï¸ æœªå‘ç°CUDAè®¾å¤‡ï¼Œä½¿ç”¨CPU")
            return 'cpu'
        
        # è·å–æ‰€æœ‰GPUä¿¡æ¯
        gpu_info = []
        for i in range(device_count):
            props = torch.cuda.get_device_properties(i)
            
            # è·å–å½“å‰å†…å­˜ä½¿ç”¨æƒ…å†µ
            torch.cuda.set_device(i)
            memory_allocated = torch.cuda.memory_allocated(i)
            memory_total = props.total_memory
            memory_free = memory_total - memory_allocated
            
            gpu_info.append({
                'id': i,
                'name': props.name,
                'total_memory': memory_total,
                'free_memory': memory_free,
                'compute_capability': f"{props.major}.{props.minor}",
                'multiprocessor_count': props.multi_processor_count
            })
            
            logger.info(f"GPU {i}: {props.name}")
            logger.info(f"  å†…å­˜: {memory_total/1e9:.1f}GB (å¯ç”¨: {memory_free/1e9:.1f}GB)")
            logger.info(f"  è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}")
            logger.info(f"  å¤šå¤„ç†å™¨æ•°é‡: {props.multi_processor_count}")
        
        # é€‰æ‹©æœ€ä½³GPUï¼ˆä¼˜å…ˆè€ƒè™‘å¯ç”¨å†…å­˜ï¼‰
        best_gpu = max(gpu_info, key=lambda x: x['free_memory'])
        best_device_id = best_gpu['id']
        
        if TORCH_AVAILABLE:
            device = torch.device(f'cuda:{best_device_id}')
        else:
            device = f'cuda:{best_device_id}'

        self.device_properties = best_gpu

        logger.info(f"âœ… é€‰æ‹©è®¾å¤‡: {device} ({best_gpu['name']})")
        return device
    
    def optimize_cuda_settings(self):
        """ä¼˜åŒ–CUDAè®¾ç½®"""
        if not TORCH_AVAILABLE or (hasattr(self.device, 'type') and self.device.type != 'cuda') or (isinstance(self.device, str) and not self.device.startswith('cuda')):
            return
        
        try:
            # è®¾ç½®å½“å‰è®¾å¤‡
            torch.cuda.set_device(self.device)
            
            # æ¸…ç†GPUç¼“å­˜
            torch.cuda.empty_cache()
            
            # è®¾ç½®å†…å­˜åˆ†é…ç­–ç•¥
            if hasattr(torch.cuda, 'set_per_process_memory_fraction'):
                torch.cuda.set_per_process_memory_fraction(self.memory_fraction, self.device)
                logger.info(f"ğŸ”§ è®¾ç½®GPUå†…å­˜ä½¿ç”¨æ¯”ä¾‹: {self.memory_fraction}")
            
            # å¯ç”¨cudnnåŸºå‡†æ¨¡å¼ï¼ˆå¦‚æœè¾“å…¥å¤§å°å›ºå®šï¼‰
            if hasattr(torch.backends.cudnn, 'benchmark'):
                torch.backends.cudnn.benchmark = True
                logger.info("ğŸš€ å¯ç”¨cuDNNåŸºå‡†æ¨¡å¼")
            
            # å¯ç”¨cudnnç¡®å®šæ€§æ¨¡å¼ï¼ˆå¯é€‰ï¼Œä¼šé™ä½æ€§èƒ½ä½†æé«˜å¯é‡ç°æ€§ï¼‰
            # torch.backends.cudnn.deterministic = True
            
            logger.info("âœ… CUDAè®¾ç½®ä¼˜åŒ–å®Œæˆ")
            
        except Exception as e:
            logger.error(f"âŒ CUDAè®¾ç½®ä¼˜åŒ–å¤±è´¥: {e}")
    
    def get_memory_info(self, device_id: Optional[int] = None):
        """è·å–GPUå†…å­˜ä¿¡æ¯"""
        if self.device.type != 'cuda':
            return {'error': 'CUDAä¸å¯ç”¨'}
        
        if device_id is None:
            device_id = self.device.index
        
        try:
            # PyTorchå†…å­˜ä¿¡æ¯
            allocated = torch.cuda.memory_allocated(device_id) / 1e9
            reserved = torch.cuda.memory_reserved(device_id) / 1e9
            max_allocated = torch.cuda.max_memory_allocated(device_id) / 1e9
            max_reserved = torch.cuda.max_memory_reserved(device_id) / 1e9
            
            # è®¾å¤‡å±æ€§
            props = torch.cuda.get_device_properties(device_id)
            total = props.total_memory / 1e9
            
            memory_info = {
                'device_id': device_id,
                'device_name': props.name,
                'total_memory': total,
                'allocated_memory': allocated,
                'reserved_memory': reserved,
                'free_memory': total - allocated,
                'max_allocated': max_allocated,
                'max_reserved': max_reserved,
                'utilization_percent': (allocated / total) * 100
            }
            
            # å¦‚æœNVMLå¯ç”¨ï¼Œè·å–æ›´è¯¦ç»†ä¿¡æ¯
            if self.nvml_initialized:
                try:
                    handle = nvml.nvmlDeviceGetHandleByIndex(device_id)
                    
                    # GPUä½¿ç”¨ç‡
                    util = nvml.nvmlDeviceGetUtilizationRates(handle)
                    memory_info['gpu_utilization'] = util.gpu
                    memory_info['memory_utilization'] = util.memory
                    
                    # æ¸©åº¦
                    temp = nvml.nvmlDeviceGetTemperature(handle, nvml.NVML_TEMPERATURE_GPU)
                    memory_info['temperature'] = temp
                    
                    # åŠŸè€—
                    power = nvml.nvmlDeviceGetPowerUsage(handle) / 1000.0  # è½¬æ¢ä¸ºç“¦ç‰¹
                    memory_info['power_usage'] = power
                    
                except Exception as e:
                    logger.debug(f"NVMLä¿¡æ¯è·å–å¤±è´¥: {e}")
            
            return memory_info
            
        except Exception as e:
            logger.error(f"è·å–GPUå†…å­˜ä¿¡æ¯å¤±è´¥: {e}")
            return {'error': str(e)}
    
    def get_all_gpu_info(self):
        """è·å–æ‰€æœ‰GPUä¿¡æ¯"""
        if not TORCH_AVAILABLE or not torch.cuda.is_available():
            return []
        
        gpu_list = []
        device_count = torch.cuda.device_count()
        
        for i in range(device_count):
            gpu_info = self.get_memory_info(i)
            gpu_list.append(gpu_info)
        
        return gpu_list
    
    def clear_cache(self):
        """æ¸…ç†GPUç¼“å­˜"""
        if self.device.type == 'cuda':
            torch.cuda.empty_cache()
            logger.info("ğŸ§¹ GPUç¼“å­˜å·²æ¸…ç†")
    
    def reset_peak_memory_stats(self):
        """é‡ç½®å³°å€¼å†…å­˜ç»Ÿè®¡"""
        if self.device.type == 'cuda':
            torch.cuda.reset_peak_memory_stats(self.device)
            torch.cuda.reset_accumulated_memory_stats(self.device)
            logger.info("ğŸ“Š GPUå†…å­˜ç»Ÿè®¡å·²é‡ç½®")
    
    @contextmanager
    def memory_monitor(self, operation_name: str = "æ“ä½œ"):
        """å†…å­˜ç›‘æ§ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""
        if self.device.type != 'cuda':
            yield
            return
        
        # è®°å½•å¼€å§‹çŠ¶æ€
        self.reset_peak_memory_stats()
        start_memory = self.get_memory_info()
        
        logger.info(f"ğŸ” å¼€å§‹ç›‘æ§ '{operation_name}' çš„GPUå†…å­˜ä½¿ç”¨")
        logger.info(f"åˆå§‹å†…å­˜: {start_memory['allocated_memory']:.2f}GB")
        
        try:
            yield
        finally:
            # è®°å½•ç»“æŸçŠ¶æ€
            end_memory = self.get_memory_info()
            peak_memory = torch.cuda.max_memory_allocated(self.device) / 1e9
            
            logger.info(f"ğŸ“Š '{operation_name}' å†…å­˜ä½¿ç”¨æŠ¥å‘Š:")
            logger.info(f"  ç»“æŸå†…å­˜: {end_memory['allocated_memory']:.2f}GB")
            logger.info(f"  å³°å€¼å†…å­˜: {peak_memory:.2f}GB")
            logger.info(f"  å†…å­˜å¢é‡: {end_memory['allocated_memory'] - start_memory['allocated_memory']:.2f}GB")
    
    def check_memory_available(self, required_gb: float) -> bool:
        """æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿçš„GPUå†…å­˜"""
        if self.device.type != 'cuda':
            return True  # CPUæ¨¡å¼æ€»æ˜¯è¿”å›True
        
        memory_info = self.get_memory_info()
        available_gb = memory_info.get('free_memory', 0)
        
        if available_gb >= required_gb:
            logger.info(f"âœ… GPUå†…å­˜å……è¶³: éœ€è¦{required_gb:.1f}GB, å¯ç”¨{available_gb:.1f}GB")
            return True
        else:
            logger.warning(f"âš ï¸ GPUå†…å­˜ä¸è¶³: éœ€è¦{required_gb:.1f}GB, å¯ç”¨{available_gb:.1f}GB")
            return False
    
    def get_optimal_batch_size(self, model_memory_gb: float, max_batch_size: int = 128) -> int:
        """æ ¹æ®GPUå†…å­˜è‡ªåŠ¨è®¡ç®—æœ€ä¼˜æ‰¹æ¬¡å¤§å°"""
        if self.device.type != 'cuda':
            return min(32, max_batch_size)  # CPUé»˜è®¤æ‰¹æ¬¡å¤§å°
        
        memory_info = self.get_memory_info()
        available_memory = memory_info.get('free_memory', 0) * self.memory_fraction
        
        # ä¼°ç®—æ¯ä¸ªæ ·æœ¬éœ€è¦çš„å†…å­˜ï¼ˆåŒ…æ‹¬æ¨¡å‹ã€æ¢¯åº¦ã€ä¼˜åŒ–å™¨çŠ¶æ€ç­‰ï¼‰
        memory_per_sample = model_memory_gb * 4  # ç»éªŒå€¼ï¼šæ¨¡å‹å¤§å°çš„4å€
        
        if memory_per_sample <= 0:
            return min(32, max_batch_size)
        
        optimal_batch_size = int(available_memory / memory_per_sample)
        optimal_batch_size = max(1, min(optimal_batch_size, max_batch_size))
        
        logger.info(f"ğŸ¯ æ¨èæ‰¹æ¬¡å¤§å°: {optimal_batch_size} (åŸºäº{available_memory:.1f}GBå¯ç”¨å†…å­˜)")
        return optimal_batch_size
    
    def supports_mixed_precision(self) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ"""
        if self.device.type != 'cuda':
            return False
        
        # æ£€æŸ¥è®¡ç®—èƒ½åŠ›ï¼ˆéœ€è¦7.0ä»¥ä¸Šæ”¯æŒTensor Coresï¼‰
        props = torch.cuda.get_device_properties(self.device)
        compute_capability = props.major + props.minor * 0.1
        
        supports_fp16 = compute_capability >= 7.0
        
        if supports_fp16:
            logger.info(f"âœ… æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ (è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor})")
        else:
            logger.info(f"âš ï¸ ä¸æ”¯æŒæ··åˆç²¾åº¦è®­ç»ƒ (è®¡ç®—èƒ½åŠ›: {props.major}.{props.minor}, éœ€è¦7.0+)")
        
        return supports_fp16
    
    def __str__(self) -> str:
        """è¿”å›CUDAç®¡ç†å™¨çš„å­—ç¬¦ä¸²è¡¨ç¤º"""
        if self.device.type == 'cpu':
            return "CUDAManager(device=CPU)"
        
        memory_info = self.get_memory_info()
        return (f"CUDAManager(device={self.device}, "
                f"memory={memory_info.get('allocated_memory', 0):.1f}GB/"
                f"{memory_info.get('total_memory', 0):.1f}GB)")


def get_cuda_info():
    """è·å–CUDAç¯å¢ƒä¿¡æ¯"""
    info = {
        'torch_available': TORCH_AVAILABLE,
        'cuda_available': False,
        'device_count': 0,
        'current_device': None,
        'cuda_version': None,
        'cudnn_version': None
    }
    
    if TORCH_AVAILABLE:
        info['cuda_available'] = torch.cuda.is_available()
        
        if torch.cuda.is_available():
            info['device_count'] = torch.cuda.device_count()
            info['current_device'] = torch.cuda.current_device()
            info['cuda_version'] = torch.version.cuda
            
            if hasattr(torch.backends.cudnn, 'version'):
                info['cudnn_version'] = torch.backends.cudnn.version()
    
    return info


def print_cuda_summary():
    """æ‰“å°CUDAç¯å¢ƒæ‘˜è¦"""
    print("ğŸ” CUDAç¯å¢ƒæ£€æŸ¥")
    print("=" * 50)
    
    info = get_cuda_info()
    
    print(f"PyTorch: {'âœ… å·²å®‰è£…' if info['torch_available'] else 'âŒ æœªå®‰è£…'}")
    
    if info['torch_available']:
        print(f"CUDA: {'âœ… å¯ç”¨' if info['cuda_available'] else 'âŒ ä¸å¯ç”¨'}")
        
        if info['cuda_available']:
            print(f"CUDAç‰ˆæœ¬: {info['cuda_version']}")
            print(f"cuDNNç‰ˆæœ¬: {info['cudnn_version']}")
            print(f"GPUæ•°é‡: {info['device_count']}")
            print(f"å½“å‰è®¾å¤‡: {info['current_device']}")
            
            # æ˜¾ç¤ºæ‰€æœ‰GPUä¿¡æ¯
            manager = CUDAManager()
            gpu_list = manager.get_all_gpu_info()
            
            for gpu in gpu_list:
                if 'error' not in gpu:
                    print(f"\nGPU {gpu['device_id']}: {gpu['device_name']}")
                    print(f"  å†…å­˜: {gpu['allocated_memory']:.1f}GB / {gpu['total_memory']:.1f}GB")
                    print(f"  ä½¿ç”¨ç‡: {gpu['utilization_percent']:.1f}%")
                    
                    if 'temperature' in gpu:
                        print(f"  æ¸©åº¦: {gpu['temperature']}Â°C")
                    if 'power_usage' in gpu:
                        print(f"  åŠŸè€—: {gpu['power_usage']:.1f}W")


if __name__ == "__main__":
    # æµ‹è¯•CUDAå·¥å…·
    print_cuda_summary()
    
    # åˆ›å»ºCUDAç®¡ç†å™¨
    manager = CUDAManager()
    print(f"\n{manager}")
    
    # æµ‹è¯•å†…å­˜ç›‘æ§
    with manager.memory_monitor("æµ‹è¯•æ“ä½œ"):
        if TORCH_AVAILABLE and torch.cuda.is_available():
            # åˆ›å»ºä¸€ä¸ªæµ‹è¯•å¼ é‡
            test_tensor = torch.randn(1000, 1000, device=manager.device)
            result = torch.matmul(test_tensor, test_tensor.T)
            del test_tensor, result
